{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess_data import get_all_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Null_TAG = 'None'\n",
    "P_TAG_b = 'Pb'  # beginning of participant phrase\n",
    "P_TAG_m = 'Pm'  # middle/end of participant phrase\n",
    "P_TAG = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "return precision, accuracy and f1 for single abstract\n",
    "for each token type (participant/intervention/outcome)\n",
    "'''\n",
    "def evaluate_abstract(gold_tags, pred_tags):\n",
    "    gold_tags = [x.replace(P_TAG_b, P_TAG) for x in gold_tags]\n",
    "    gold_tags = np.array([x.replace(P_TAG_m, P_TAG) for x in gold_tags])\n",
    "    pred_tags = [x.replace(P_TAG_b, P_TAG) for x in pred_tags]\n",
    "    pred_tags = np.array([x.replace(P_TAG_m, P_TAG) for x in pred_tags])\n",
    "\n",
    "    unique, counts = np.unique(pred_tags, return_counts=True)\n",
    "    pred_tag_dict = dict(zip(unique, counts))\n",
    "    p_tokens_extracted = pred_tag_dict[P_TAG]\n",
    "\n",
    "    intersection = (gold_tags == pred_tags)\n",
    "    p_tokens = (gold_tags == P_TAG) \n",
    "    p_tokens_correct = (((intersection*1)+(p_tokens*1)))== 2\n",
    "\n",
    "    unique, counts = np.unique(p_tokens_correct, return_counts=True)\n",
    "    p_tokens_correct_tag_dict = dict(zip(unique, counts))\n",
    "    p_tokens_correct = p_tokens_correct_tag_dict[True]\n",
    "    \n",
    "    unique, counts = np.unique(gold_tags, return_counts=True)\n",
    "    gold_tag_dict = dict(zip(unique, counts))\n",
    "    p_true_tokens = gold_tag_dict[P_TAG]\n",
    "    \n",
    "#     print \"tokens extracted correctly: \", p_tokens_correct\n",
    "#     print \"tokens extracted: \", p_tokens_extracted\n",
    "#     print \"true tokens: \", p_true_tokens\n",
    "    \n",
    "    p_precision = float(p_tokens_correct)/float(p_tokens_extracted)\n",
    "    p_recall = float(p_tokens_correct)/float(p_true_tokens)\n",
    "    p_f1 = (2*p_precision*p_recall)/(p_precision+p_recall)\n",
    "#     print \"precision: \", p_precision\n",
    "#     print \"recall: \", p_recall\n",
    "#     print \"f1: \", p_f1\n",
    "    \n",
    "    return (p_precision, p_recall, p_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens extracted correctly:  8\n",
      "tokens extracted:  8\n",
      "true tokens:  12\n",
      "precision:  1.0\n",
      "recall:  0.666666666667\n",
      "f1:  0.8\n"
     ]
    }
   ],
   "source": [
    "# evaluate_abstract(test, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
