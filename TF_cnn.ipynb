{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x111b3c610>> ignored\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preprocess_data import get_all_data_train\n",
    "from TF_preprocess_data import get_1_hot_abstract_encodings\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "# dennybritz's Sentance classification using cnn\n",
    "# https://github.com/dennybritz/cnn-text-classification-tf\n",
    "# njl's Sentiment Analysis example \n",
    "# https://github.com/nicholaslocascio/tensorflow-nlp-tutorial/blob/master/sentiment-analysis/Sentiment-RNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BATCH_SIZE=64\n",
      "CHECKPOINT_EVERY=100\n",
      "DEV_SAMPLE_PERCENTAGE=0.1\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EMBEDDING_DIM=128\n",
      "EVALUATE_EVERY=100\n",
      "FILTER_SIZES=3,4,5\n",
      "L2_REG_LAMBDA=0.0\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "NEGATIVE_DATA_FILE=./data/rt-polaritydata/rt-polarity.neg\n",
      "NUM_EPOCHS=200\n",
      "NUM_FILTERS=128\n",
      "POSITIVE_DATA_FILE=./data/rt-polaritydata/rt-polarity.pos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data loading params\n",
    "tf.flags.DEFINE_float(\"dev_sample_percentage\", .1, \"Percentage of the training data to use for validation\")\n",
    "tf.flags.DEFINE_string(\"positive_data_file\", \"./data/rt-polaritydata/rt-polarity.pos\", \"Data source for the positive data.\")\n",
    "tf.flags.DEFINE_string(\"negative_data_file\", \"./data/rt-polaritydata/rt-polarity.neg\", \"Data source for the positive data.\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 128, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.flags.DEFINE_string(\"filter_sizes\", \"3,4,5\", \"Comma-separated filter sizes (default: '3,4,5')\")\n",
    "tf.flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 128)\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.0, \"L2 regularizaion lambda (default: 0.0)\")\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64, \"Batch Size (default: 64)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 200, \"Number of training epochs (default: 200)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 100, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 100, \"Save model after this many steps (default: 100)\")\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_array, tag_array = get_all_data_train()\n",
    "X, Y = get_1_hot_abstract_encodings(word_array, tag_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_placeholder = tf.placeholder(tf.float32, name='data_placeholder')\n",
    "labels_placeholder = tf.placeholder(tf.float32, name='labels_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ef9431223f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeed_dict_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdata_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_placeholder\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob_rate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_data' is not defined"
     ]
    }
   ],
   "source": [
    "feed_dict_train = {data_placeholder: batch_data, labels_placeholder : batch_labels, keep_prob_placeholder: keep_prob_rate}\n",
    "_, loss_value_train, predictions_value_train, accuracy_value_train = session.run(\n",
    "      [optimizer, loss, prediction, accuracy], feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# After then, we can use :\n",
    "# input = tf.placeholder(tf.float32) #not intialized and contains no data \n",
    "# classifier = ...\n",
    "# print(classifier.eval(feed_dict={input: my_python_preprocessing_fn()}))\n",
    "\n",
    "##### More to another file #####\n",
    "\n",
    "def placeholder_inputs(batch_size):\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\n",
    "                                                         mnist.IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder\n",
    "\n",
    "\n",
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "    images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size,\n",
    "                                                 FLAGS.fake_data)\n",
    "    feed_dict = {\n",
    "      images_pl: images_feed,\n",
    "      labels_pl: labels_feed,\n",
    "    }\n",
    "    \n",
    "    return feed_dict\n",
    "\n",
    "# how to we write this dataset? \n",
    "\n",
    "# placeholders, which allow you to manually pass in numpy arrays of data.\n",
    "with tf.Session():\n",
    "  input = tf.placeholder(tf.float32) #not intialized and contains no data \n",
    "  classifier = ...\n",
    "  print(classifier.eval(feed_dict={input: my_python_preprocessing_fn()}))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[2, 2])\n",
    "y = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "z = tf.matmul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
