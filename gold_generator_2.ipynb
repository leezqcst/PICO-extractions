{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Run this first. This aggregates human annotations\n",
    "and generates gold annotations.\n",
    "\n",
    "New version that selects only parts of the union\n",
    "that correspond to at least half of the phrases\n",
    "that make up the union.\n",
    "'''\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory for annotations\n",
    "directory = 'PICO-annotations/interventions_batch5k'\n",
    "\n",
    "# Minimum number of count that a phrase must have\n",
    "# to be included in the gold annotations\n",
    "threshold = 3\n",
    "\n",
    "# Suffixes for the generated files\n",
    "machine_suffix = '_gold.ann'\n",
    "human_suffix = '_gold_human_readable.ann'\n",
    "\n",
    "tokens_suffix = '_tokens.txt'\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# For each subdirectory\n",
    "for subdir in os.listdir(directory):\n",
    "    subdir_path = directory + '/' + subdir\n",
    "    \n",
    "    # Not a directory\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "    \n",
    "    # For each abstract in subdirectory\n",
    "    for abstract in os.listdir(subdir_path):\n",
    "        if abstract[-4:] == '.txt' and tokens_suffix not in abstract:\n",
    "            abstract_index = abstract[:-4]\n",
    "            \n",
    "            '''Step 1: Gather all annotations'''\n",
    "            \n",
    "            # This stores entries of the form\n",
    "            # ('Participants', [[34, 65], [344, 375], ...])\n",
    "            # [34, 65] means a Participants phrase starting at 34 and ending at 65\n",
    "            dictionary = defaultdict(list)\n",
    "            \n",
    "            # Go through each associated annotation\n",
    "            for annotation in os.listdir(subdir_path):\n",
    "                # Don't include our gold annotations!\n",
    "                if annotation[-4:] == '.ann' and annotation.startswith(abstract_index) \\\n",
    "                and machine_suffix not in annotation and human_suffix not in annotation:\n",
    "                    f = open(subdir_path + '/' + annotation)\n",
    "                    \n",
    "                    # Read each line\n",
    "                    for line in f.readlines():\n",
    "                        tokens = line.split()\n",
    "                        \n",
    "                        # This is e.g. 'Participants'\n",
    "                        pico_type = tokens[1]\n",
    "                        \n",
    "                        # Sometimes this comes up. It does not provide pico tags so we skip it.\n",
    "                        if pico_type == 'AnnotatorNotes':\n",
    "                            continue\n",
    "                        \n",
    "                        # Bad formatting that comes up\n",
    "                        if ';' in tokens[3]:\n",
    "                            continue\n",
    "                        \n",
    "                        # Start and end of this phrase\n",
    "                        start = int(tokens[2])\n",
    "                        end = int(tokens[3])\n",
    "                        \n",
    "                        dictionary[pico_type].append([start, end])\n",
    "                    \n",
    "                    f.close()\n",
    "            \n",
    "            # Sort each list in dictionary according to start values\n",
    "            for instance_list in dictionary.values():\n",
    "                instance_list.sort(key=lambda x: x[0])\n",
    "            \n",
    "            if DEBUG:\n",
    "                if abstract_index == '10492627':\n",
    "                    print dictionary\n",
    "            \n",
    "            '''Step 2: Aggregate the annotations'''\n",
    "            \n",
    "            # Build an aggregate dictionary\n",
    "            # by combining all [start, end] pairs that overlap\n",
    "            # into the same \"interval\" and count the number of overlapped pairs\n",
    "            # Format: ('Participants', [[20, 120, 3], [143, 165, 2], ...])\n",
    "            # [20, 120, 3] means an interval starting at 20 and ending at 120\n",
    "            # which is built from combining 3 different phrases\n",
    "            aggregate_dict = defaultdict(list)\n",
    "            \n",
    "            for pico_type, instance_list in dictionary.iteritems():\n",
    "                # Keep track of the start and end of current interval,\n",
    "                # and the number of phrases the interval is made up of\n",
    "                curr_start = None\n",
    "                curr_end = None\n",
    "                num_phrases = 0\n",
    "                \n",
    "                for start, end in instance_list:\n",
    "                    if num_phrases == 0:\n",
    "                        # There is no current interval\n",
    "                        curr_start = start\n",
    "                        curr_end = end\n",
    "                        num_phrases = 1\n",
    "                    elif start < curr_end:\n",
    "                        # This phrase overlaps with the current interval,\n",
    "                        # so update the current interval.\n",
    "                        curr_end = max(curr_end, end)\n",
    "                        num_phrases += 1\n",
    "                    else:\n",
    "                        # This phrase does not overlap with the current interval,\n",
    "                        # so store the current inverval and start over.\n",
    "                        if num_phrases >= threshold:\n",
    "                            aggregate_dict[pico_type].append([curr_start, curr_end, num_phrases])\n",
    "                        \n",
    "                        curr_start = start\n",
    "                        curr_end = end\n",
    "                        num_phrases = 1\n",
    "                \n",
    "                # Store the last interval\n",
    "                if num_phrases >= threshold:\n",
    "                    aggregate_dict[pico_type].append([curr_start, curr_end, num_phrases])\n",
    "            \n",
    "            if DEBUG:\n",
    "                if abstract_index == '10492627':\n",
    "                    print aggregate_dict\n",
    "            \n",
    "            '''Step 3: Filter each interval to get gold annotations'''\n",
    "            \n",
    "            # For each interval in aggregate_dict that is made up of num_phrases phrases,\n",
    "            # select only the parts that are contained in at least num_phrases/2 phrases.\n",
    "            # Same format as aggregate_dict\n",
    "            gold_dict = defaultdict(list)\n",
    "            \n",
    "            for pico_type in dictionary.keys():\n",
    "                # First, build a list of start and end points of all phrases\n",
    "                boundaries = set()\n",
    "                \n",
    "                for start, end in dictionary[pico_type]:\n",
    "                    boundaries.add(start)\n",
    "                    boundaries.add(end)\n",
    "                    \n",
    "                boundaries = list(boundaries)\n",
    "                boundaries.sort()\n",
    "                \n",
    "                # Now tally the number of times each part appears\n",
    "                # ex. boundaries = [20, 25, 32, 37, 45, ...]\n",
    "                # If [25, 37] appears, we add 1 to tally_dict[25] and tally_dict[32]\n",
    "                tally_dict = defaultdict(int)\n",
    "                \n",
    "                for start, end in dictionary[pico_type]:\n",
    "                    for boundary in boundaries:\n",
    "                        if boundary >= start and boundary < end:\n",
    "                            tally_dict[boundary] += 1\n",
    "                \n",
    "                # Iterate through all intervals\n",
    "                for start_interval, end_interval, num_phrases in aggregate_dict[pico_type]:\n",
    "                    # Keep track of the start of the current gold interval\n",
    "                    curr_start = None\n",
    "                    \n",
    "                    for boundary in boundaries:\n",
    "                        # Consider only boundaries within the interval\n",
    "                        if boundary >= start_interval and boundary <= end_interval:\n",
    "                            if tally_dict[boundary] >= (num_phrases + 1)/2 and boundary < end_interval:\n",
    "                                # This part should be included, so set it to be the\n",
    "                                # current start of the gold interval if not exist.\n",
    "                                if curr_start == None:\n",
    "                                    curr_start = boundary\n",
    "                            else:\n",
    "                                # This part should not be included, so store\n",
    "                                # the current gold interval and reset.\n",
    "                                if curr_start is not None:\n",
    "                                    gold_dict[pico_type].append([curr_start, boundary, num_phrases])\n",
    "                                    curr_start = None\n",
    "            \n",
    "            if DEBUG:\n",
    "                if abstract_index == '10492627':\n",
    "                    print gold_dict\n",
    "            \n",
    "            '''Step 4: Write out results'''\n",
    "            \n",
    "            # Write gold annotations for system input\n",
    "            # Format: Participants 20 120 345 678 ...\n",
    "            f = open(subdir_path + '/' + abstract_index + machine_suffix, 'w')\n",
    "            \n",
    "            for pico_type, instance_list in gold_dict.iteritems():\n",
    "                f.write(pico_type + ' ')\n",
    "                \n",
    "                for start, end, num_phrases in instance_list:\n",
    "                    f.write(str(start) + ' ' + str(end) + ' ')\n",
    "                \n",
    "                f.write('\\n')\n",
    "            \n",
    "            f.close()\n",
    "            \n",
    "            # Now write a human readable one\n",
    "            # Format: Participants [start] [end] [num_phrases]\n",
    "            # [corresponding text]\n",
    "            \n",
    "            # First get the abstract text\n",
    "            abstract_file = open(subdir_path + '/' + abstract)\n",
    "            abstract_text = abstract_file.read()\n",
    "            abstract_file.close()\n",
    "            \n",
    "            f = open(subdir_path + '/' + abstract_index + human_suffix, 'w')\n",
    "            \n",
    "            for pico_type, instance_list in gold_dict.iteritems():\n",
    "                for start, end, num_phrases in instance_list:\n",
    "                    f.write(pico_type + ' ')\n",
    "                    f.write(str(start) + ' ' + str(end) + ' ' + str(num_phrases))\n",
    "                    f.write('\\n')\n",
    "                    \n",
    "                    f.write(abstract_text[start:end])\n",
    "                    f.write('\\n')\n",
    "            \n",
    "            f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
