{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from preprocess_data import get_all_data_train\n",
    "from preprocess_data import get_all_data_dev\n",
    "from preprocess_data import get_all_data_test\n",
    "from evaluation import eval_abstracts_avg\n",
    "from evaluation import eval_abstracts\n",
    "from evaluation import evaluate_abstract_PRF1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Hot features: Function to return x and Y from words and tags.\n",
    "X contains W_t-n...W_t and Z_t-n...Z_t-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf2_1hot_get_X_Y_dictlist(words, tags, n, dict_vectorizer=None):\n",
    "    dict_list = []\n",
    "    Y = []\n",
    "    for sentance_index in range(0, len(words)):\n",
    "        sentance = words[sentance_index]\n",
    "        tag_list = tags[sentance_index]\n",
    "        for word_ind in range(0, len(sentance)):\n",
    "            word_dict = {}\n",
    "            for i in range(0,n):\n",
    "                w_id = \"wt-\"+str(i)\n",
    "                if i > word_ind:\n",
    "                    word_dict[w_id] = '*'\n",
    "                else:\n",
    "                    word_dict[w_id] = sentance[word_ind-i]\n",
    "                    \n",
    "            for i in range(1, n):\n",
    "                z_id=\"zt-\"+str(i)\n",
    "                if i > word_ind:\n",
    "                    word_dict[z_id] = '*'\n",
    "                else:\n",
    "                    word_dict[z_id] = tag_list[word_ind-i]#get_correct_tag((word_ind-i), (word_ind-i-1), tag_list)\n",
    "#             word_dict.update(get_dict_extra_features(sentance[word_ind]))\n",
    "            dict_list.append(word_dict)\n",
    "            Y.append(tag_list[word_ind])\n",
    "            \n",
    "    #for i in range(0, 300):\n",
    "    #    if (Y[i] != 0):\n",
    "    #        print \"word: \", dict_list[i]['wt-0'], \"  tag: \", Y[i]\n",
    "    \n",
    "    return dict_list, Y\n",
    "        \n",
    "    if dict_vectorizer == None:\n",
    "        dict_vectorizer = DictVectorizer()\n",
    "        X = dict_vectorizer.fit_transform(dict_list)\n",
    "    else:\n",
    "        X = dict_vectorizer.transform(dict_list)\n",
    "    return [X, Y, dict_vectorizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clf2_X_train(dict_list, dict_vectorizer=None):\n",
    "    if dict_vectorizer == None:\n",
    "        dict_vectorizer = DictVectorizer()\n",
    "        X = dict_vectorizer.fit_transform(dict_list)\n",
    "    else:\n",
    "        X = dict_vectorizer.transform(dict_list)\n",
    "    return X, dict_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train classifier clf2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_clf2(X_train, Y_train, c=1.0):\n",
    "    clf2 = LogisticRegression(random_state=123, C=c, penalty='l1')\n",
    "    clf2.fit(X_train, Y_train)\n",
    "    return clf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict tags using clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_tags_clf2(clf2, dev_words, n, dict_vectorizer):\n",
    "    Y_pred= []\n",
    "    index = 0;\n",
    "    for sentance_index in range(0, len(dev_words)): # for the sentence \n",
    "        sentance = dev_words[sentance_index]\n",
    "        # tag_list = tags[sentance_index]\n",
    "        for word_ind in range(0, len(sentance)):\n",
    "            word_dict = {}\n",
    "            for i in range(0,n):\n",
    "                w_id = \"wt-\"+str(i)\n",
    "                if i > word_ind:\n",
    "                    word_dict[w_id] = '*'\n",
    "                else:\n",
    "                    word_dict[w_id] = sentance[word_ind-i]\n",
    "                    \n",
    "            for i in range(1, n):\n",
    "                z_id=\"zt-\"+str(i)\n",
    "                tag_ind = index-i\n",
    "                if (i > word_ind or tag_ind < 0):\n",
    "                    word_dict[z_id] = '*'\n",
    "                else:\n",
    "                    word_dict[z_id] = Y_pred[tag_ind]\n",
    "#             word_dict.update(get_dict_extra_features(sentance[word_ind]))\n",
    "            index += 1\n",
    "            x_t = dict_vectorizer.transform([word_dict])\n",
    "            y_t = clf2.predict(x_t)\n",
    "            Y_pred.extend(y_t)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_tr, tags_tr = get_all_data_train()\n",
    "words_test, tags_test = get_all_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "dict_list, Y_train = clf2_1hot_get_X_Y_dictlist(words_tr, tags_tr, n)\n",
    "X_train, dict_vectorizer = get_clf2_X_train(dict_list, dict_vectorizer=None)\n",
    "clf2 = train_clf2(X_train, Y_train, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_tr = predict_tags_clf2(clf2, words_tr, n, dict_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_list_other, Y_test = clf2_1hot_get_X_Y_dictlist(words_test, tags_test, n)\n",
    "Y_pred = predict_tags_clf2(clf2, words_test, n, dict_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45508474576271185, 0.3417583416674243, 0.3903629471935199)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_abstract_PRF1(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5525869454984176, 0.397052541648868, 0.46208283071974265)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_abstract_PRF1(Y_train, Y_pred_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_dev, tags_dev = get_all_data_dev()\n",
    "dict_list_other, Y_dev = clf2_1hot_get_X_Y_dictlist(words_dev, tags_dev, n)\n",
    "Y_pred_dev = predict_tags_clf2(clf2, words_dev, n, dict_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48671446646984395, 0.3654872862184418, 0.41747848781622265)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_abstract_PRF1(Y_dev, Y_pred_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4817688551275095, 0.4017283503755316, 0.43812296457120303)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_tr, tags_tr = get_all_data_train()\n",
    "n = 3\n",
    "dict_list, Y_train = clf2_1hot_get_X_Y_dictlist(words_tr, tags_tr, n)\n",
    "X_train, dict_vectorizer = get_clf2_X_train(dict_list, dict_vectorizer=None)\n",
    "clf2 = train_clf2(X_train, Y_train, 7.0)\n",
    "\n",
    "words_dev, tags_dev = get_all_data_dev()\n",
    "dict_list_other, Y_dev = clf2_1hot_get_X_Y_dictlist(words_dev, tags_dev, n)\n",
    "Y_pred_dev = predict_tags_clf2(clf2, words_dev, n, dict_vectorizer)\n",
    "\n",
    "evaluate_abstract_PRF1(Y_dev, Y_pred_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_tr, tags_tr = get_all_data_train()\n",
    "words_dev, tags_dev = get_all_data_dev()\n",
    "n = 3\n",
    "\n",
    "max_f1 = 0.0\n",
    "best_reg = None\n",
    "for reg_param in [1.0, 3.0, 5.0, 7.0, 10.0]:\n",
    "    dict_list, Y_train = clf2_1hot_get_X_Y_dictlist(words_tr, tags_tr, n)\n",
    "    X_train, dict_vectorizer = get_clf2_X_train(dict_list, dict_vectorizer=None)\n",
    "    clf2 = train_clf2(X_train, Y_train, reg_param)\n",
    "\n",
    "    dict_list_other, Y_dev = clf2_1hot_get_X_Y_dictlist(words_dev, tags_dev, n)\n",
    "    Y_pred_dev = predict_tags_clf2(clf2, words_dev, n, dict_vectorizer)\n",
    "    P, R, F1 = evaluate_abstract_PRF1(Y_dev, Y_pred_dev)\n",
    "    if (F1 > max_f1):\n",
    "        max_f1 = F1\n",
    "        best_reg = reg_param\n",
    "print max_f1\n",
    "print best_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_tr, tags_tr = get_all_data_train()\n",
    "n = 5\n",
    "dict_list, Y_train = clf2_1hot_get_X_Y_dictlist(words_tr, tags_tr, n)\n",
    "X_train, dict_vectorizer = get_clf2_X_train(dict_list, dict_vectorizer=None)\n",
    "clf2 = train_clf2(X_train, Y_train, 7.0)\n",
    "\n",
    "words_dev, tags_dev = get_all_data_dev()\n",
    "dict_list_other, Y_dev = clf2_1hot_get_X_Y_dictlist(words_dev, tags_dev, n)\n",
    "Y_pred_dev = predict_tags_clf2(clf2, words_dev, n, dict_vectorizer)\n",
    "\n",
    "evaluate_abstract_PRF1(Y_dev, Y_pred_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
