{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DEBUG VERSION\n",
    "# fixes gold annotations to not index based on white space\n",
    "def fix_gold_annotations_debug(abstract_path, gold_annotation_path):\n",
    "    abs_file = open(abstract_path, 'r');\n",
    "    text = abs_file.read()\n",
    "    \n",
    "    ann_file = open(gold_annotation_path, 'r');\n",
    "    anns = ann_file.read()\n",
    "    anns = anns.strip().split(' ')[1:]\n",
    "    \n",
    "#     print anns\n",
    "    \n",
    "    anns = [int(x) for x in anns]\n",
    "#     print anns\n",
    "    \n",
    "    clean_path = abstract_path[:-4] + '_tokens.txt'\n",
    "    clean_file = open(clean_path, 'r')\n",
    "    clean_text = clean_file.read().replace(' ', '')\n",
    "    \n",
    "#     print text\n",
    "#     print ' '\n",
    "#     print clean_text\n",
    "    \n",
    "    new_anns = []\n",
    "    \n",
    "    for ann_index in anns: \n",
    "        white = text[0:ann_index].count(' ')\n",
    "        white += text[0:ann_index].count('\\n')\n",
    "        white -= text[0:ann_index].count('\"')\n",
    "        new_anns.append(ann_index-white)\n",
    "#     print ' '\n",
    "    \n",
    "#     print anns\n",
    "#     print new_anns\n",
    "    \n",
    "    for i in range(0, len(anns), 2):\n",
    "        old = text[anns[i]:anns[i+1]]\n",
    "        new = clean_text[new_anns[i]:new_anns[i+1]]\n",
    "        old = old.replace(' ', '')\n",
    "        \n",
    "        old = old.replace('\"', \"''\").replace('\\n', '');\n",
    "        new = new.replace('``', \"''\").replace('\\n', '')\n",
    "        if not(old == new):\n",
    "            print \"abstract: \", abs_file\n",
    "            print \"original phrase length: \", len(old), \";  new length: \", len(new)\n",
    "            print old\n",
    "            print new\n",
    "            print \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# abstract = 'PICO-annotations/batch5k/0074f5e102cf4409ac07f6209dd30144/9665186.txt'\n",
    "# annpath = 'PICO-annotations/batch5k/0074f5e102cf4409ac07f6209dd30144/9665186_gold.ann'\n",
    "\n",
    "# abstract = 'PICO-annotations/batch5k/017e0bd245aa46b0bf1737ba34a30b2e/2648816.txt'\n",
    "# annpath ='PICO-annotations/batch5k/017e0bd245aa46b0bf1737ba34a30b2e/2648816_gold.ann'\n",
    "\n",
    "# fix_gold_annotations_debug(abstract, annpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fixes gold annotations to not index based on white space\n",
    "def fix_gold_annotations(abstract_path, gold_annotation_path, TYPE='Participants'):\n",
    "    abs_file = open(abstract_path, 'r');\n",
    "    text = abs_file.read()\n",
    "    \n",
    "    ann_file = open(gold_annotation_path, 'r');\n",
    "    anns = ann_file.read()\n",
    "    anns = anns.strip().split(' ')[1:]\n",
    "        \n",
    "    anns = [int(x) for x in anns]\n",
    "    \n",
    "    new_anns = []\n",
    "    \n",
    "    for ann_index in anns: \n",
    "        white = text[0:ann_index].count(' ')\n",
    "        white += text[0:ann_index].count('\\n')\n",
    "        white -= text[0:ann_index].count('\"')\n",
    "        new_anns.append(ann_index-white)\n",
    "\n",
    "    new_ann_path = gold_annotation_path[:-4] + '_2.ann'\n",
    "    new_ann_file = open(new_ann_path, 'w');\n",
    "    new_anns_str = [str(x) for x in new_anns]\n",
    "    out = TYPE + ' ' + ' '.join(new_anns_str)\n",
    "    new_ann_file.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# abstract ='PICO-annotations/batch5k/287c157f63e44612bd3f036004df2111/22727707.txt'\n",
    "# annpath ='PICO-annotations/batch5k/287c157f63e44612bd3f036004df2111/22727707_gold.ann'\n",
    "\n",
    "# fix_gold_annotations(abstract, annpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = 'PICO-annotations/batch5k'\n",
    "\n",
    "# For each subdirectory\n",
    "for subdir in os.listdir(directory):\n",
    "    subdir_path = directory + '/' + subdir\n",
    "    # print subdir_path\n",
    "    \n",
    "    # Not a directory\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "    \n",
    "    # For each abstract in subdirectory\n",
    "    for abstract in os.listdir(subdir_path):\n",
    "        if (abstract.endswith('.txt')) and not (abstract.endswith('tokens.txt')):\n",
    "            abstract_path = subdir_path + '/' + abstract; \n",
    "            # print abstract_path\n",
    "            ann_path = abstract_path[0:-4] + '_gold.ann'\n",
    "            fix_gold_annotations(abstract_path, ann_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # TEST\n",
    "# directory = 'PICO-annotations/batch5k'\n",
    "\n",
    "# # For each subdirectory\n",
    "# for subdir in os.listdir(directory):\n",
    "#     subdir_path = directory + '/' + subdir\n",
    "#     # print subdir_path\n",
    "    \n",
    "#     # Not a directory\n",
    "#     if not os.path.isdir(subdir_path):\n",
    "#         continue\n",
    "    \n",
    "#     # For each abstract in subdirectory\n",
    "#     for abstract in os.listdir(subdir_path):\n",
    "#         if (abstract.endswith('.txt')) and not (abstract.endswith('tokens.txt')):\n",
    "#             abstract_path = subdir_path + '/' + abstract; \n",
    "#             # print abstract_path\n",
    "#             ann_path = abstract_path[0:-4] + '_gold.ann'\n",
    "#             fix_gold_annotations_debug(abstract_path, ann_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fix intervention gold annotations to be white space independant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = 'PICO-annotations/batch5k'\n",
    "i_directory = 'PICO-annotations/interventions_batch5k'\n",
    "\n",
    "# For each subdirectory\n",
    "for subdir in os.listdir(directory):\n",
    "    subdir_path = directory + '/' + subdir\n",
    "    ann_subdir_path =  i_directory + '/' + subdir\n",
    "    # print subdir_path\n",
    "    \n",
    "    # Not a directory\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "    \n",
    "    # For each abstract in subdirectory\n",
    "    for abstract in os.listdir(subdir_path):\n",
    "        if (abstract.endswith('.txt')) and not (abstract.endswith('tokens.txt')):\n",
    "            abstract_path = subdir_path + '/' + abstract; \n",
    "            ann_path = ann_subdir_path +'/' + abstract; \n",
    "            # print abstract_path\n",
    "            ann_path = ann_path[0:-4] + '_gold.ann'\n",
    "            fix_gold_annotations(abstract_path, ann_path, TYPE='Intervention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "[0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "[1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
    "truth = np.array([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "print type(predictions)\n",
    "\n",
    "print type(truth)\n",
    "\n",
    "print predictions\n",
    "\n",
    "print truth\n",
    "\n",
    "print len(predictions)\n",
    "\n",
    "print len(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1]\n",
      "[0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "{0: 47, 1: 17}\n",
      "47\n",
      " ------------------------------------------------------ \n",
      "[False False False False  True False False  True False  True  True  True\n",
      " False False False False  True  True  True  True  True False False False\n",
      " False  True False False False  True False  True False False  True False\n",
      "  True False  True False False False False  True False False False False\n",
      " False False False False False False  True False False False  True False\n",
      " False  True False False]\n",
      "\n",
      "[False  True False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False  True False False False False\n",
      "  True False False False False False False False False False False  True\n",
      " False False False False False False False False False False  True False\n",
      " False False False False]\n",
      "\n",
      "[False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False  True False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False False]\n",
      "(47, 5, 7)\n"
     ]
    }
   ],
   "source": [
    "gold_tags = truth\n",
    "pred_tags = predictions\n",
    "print gold_tags\n",
    "print pred_tags\n",
    "\n",
    "unique, counts = np.unique(pred_tags, return_counts=True)\n",
    "pred_tag_dict = dict(zip(unique, counts))\n",
    "p_tokens_extracted = pred_tag_dict[0]\n",
    "print pred_tag_dict\n",
    "print p_tokens_extracted\n",
    "\n",
    "intersection = (gold_tags == pred_tags)\n",
    "p_tokens = (gold_tags == 0) \n",
    "p_tokens_correct = (((intersection*1)+(p_tokens*1)))== 2\n",
    "print \" ------------------------------------------------------ \"\n",
    "print intersection\n",
    "print \"\"\n",
    "print p_tokens\n",
    "print \"\"\n",
    "print p_tokens_correct\n",
    "\n",
    "unique, counts = np.unique(p_tokens_correct, return_counts=True)\n",
    "p_tokens_correct_tag_dict = dict(zip(unique, counts))\n",
    "p_tokens_correct = p_tokens_correct_tag_dict[True]\n",
    "\n",
    "unique, counts = np.unique(gold_tags, return_counts=True)\n",
    "gold_tag_dict = dict(zip(unique, counts))\n",
    "p_true_tokens = gold_tag_dict[0]\n",
    "\n",
    "print (p_tokens_extracted, p_tokens_correct, p_true_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
