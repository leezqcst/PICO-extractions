{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF Support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_data(data_set, tag):\n",
    "    switcher = {\n",
    "        'train': 'PICO-annotations/train_abstracts.txt',\n",
    "        'dev': 'PICO-annotations/dev_abstracts.txt',\n",
    "        'test': 'PICO-annotations/test_abstracts.txt', \n",
    "    }\n",
    "    \n",
    "    path = switcher[data_set]\n",
    "    abstract_file = open(path, 'r')\n",
    "    abstracts = abstract_file.readlines()\n",
    "    abstract_file.close()\n",
    "    \n",
    "    abstracts = [x.strip() for x in abstracts]\n",
    "    \n",
    "    tokens_array = []\n",
    "    tags_array = []\n",
    "    \n",
    "    for abstract_path in abstracts:\n",
    "        token_path = '{}_tokens.txt'.format(abstract_path[:-4])\n",
    "        tag_path = '{}_{}_tokens_tags.ann'.format(abstract_path[:-4], tag)\n",
    "        \n",
    "        f = open(token_path, 'r')\n",
    "        tokens = f.read().split()\n",
    "        f.close()\n",
    "        \n",
    "        f = open(tag_path, 'r')\n",
    "        tags = f.read().split()\n",
    "        f.close()\n",
    "        \n",
    "        if len(tokens) != len(tags):\n",
    "            raise ValueError('For this file, len of abstract words and tags did not match.', abstract_path)\n",
    "        \n",
    "        tokens_array.append(tokens)\n",
    "        tags_array.append(tags)\n",
    "    \n",
    "    if len(tokens_array) != len(tags_array):\n",
    "        raise ValueError('Overall, len of abstract words and tags did not match.')\n",
    "    \n",
    "    return tokens_array, tags_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_tags(pred_tags_list, gold_tags_list, eval_tag):\n",
    "    count_pred = defaultdict(int)\n",
    "    length_pred = defaultdict(int)\n",
    "    count_gold = defaultdict(int)\n",
    "    length_gold = defaultdict(int)\n",
    "        \n",
    "    for i in range(len(pred_tags_list)):\n",
    "        pred_tags = pred_tags_list[i]\n",
    "        gold_tags = gold_tags_list[i]\n",
    "\n",
    "        def to_intervals(tags):\n",
    "            intervals = []\n",
    "            curr_start = None\n",
    "\n",
    "            for j in range(len(tags)+1):\n",
    "                if j == len(tags):\n",
    "                    if curr_start != None:\n",
    "                        intervals.append((curr_start, j))\n",
    "                        curr_start = None\n",
    "                elif tags[j] == eval_tag:\n",
    "                    if curr_start == None:\n",
    "                        curr_start = j\n",
    "                else:\n",
    "                    if curr_start != None:\n",
    "                        intervals.append((curr_start, j))\n",
    "                        curr_start = None\n",
    "\n",
    "            return intervals\n",
    "    \n",
    "        pred_intervals = to_intervals(pred_tags)\n",
    "        gold_intervals = to_intervals(gold_tags)\n",
    "        \n",
    "        def evaluate_intervals(source_intervals, target_intervals, count_dict, length_dict):\n",
    "            def relationship(interval_1, interval_2):\n",
    "                a, b = interval_1\n",
    "                c, d = interval_2\n",
    "\n",
    "                if a == c and b == d:\n",
    "                    return 'Identical'\n",
    "                elif b <= c or d <= a:\n",
    "                    return 'Non-overlapping'\n",
    "                elif c <= a and b <= d:\n",
    "                    return 'Subinterval'\n",
    "                elif a <= c and d <= b:\n",
    "                    return 'Superinterval'\n",
    "                else:\n",
    "                    return 'Overlapping'\n",
    "\n",
    "            def one_to_many_relationship(interval, intervals):\n",
    "                encountered = set()\n",
    "                for target_interval in intervals:\n",
    "                    relation = relationship(interval, target_interval)\n",
    "                    encountered.add(relation)\n",
    "\n",
    "                for relation in ['Identical', 'Subinterval', 'Superinterval', 'Overlapping']:\n",
    "                    if relation in encountered:\n",
    "                        return relation\n",
    "\n",
    "                return 'Non-overlapping'\n",
    "            \n",
    "            for interval in source_intervals:\n",
    "                \n",
    "                relation = one_to_many_relationship(interval, target_intervals)\n",
    "                \n",
    "                a, b = interval\n",
    "                \n",
    "                count_dict[relation] += 1\n",
    "                length_dict[relation] += b-a\n",
    "            \n",
    "            return\n",
    "        \n",
    "        evaluate_intervals(pred_intervals, gold_intervals, count_pred, length_pred)\n",
    "        evaluate_intervals(gold_intervals, pred_intervals, count_gold, length_gold)\n",
    "    \n",
    "    def print_result(count_pred, length_pred, count_gold, length_gold):\n",
    "        types = ['Identical', 'Subinterval', 'Superinterval', 'Overlapping', 'Non-overlapping']\n",
    "        \n",
    "        switcher = [\n",
    "            (count_pred, 'predicted', 'intervals'),\n",
    "            (length_pred, 'predicted', 'tokens'),\n",
    "            (count_gold, 'gold', 'intervals'),\n",
    "            (length_gold, 'gold', 'tokens')\n",
    "        ]\n",
    "        \n",
    "        for dictionary, p_or_g, i_or_t in switcher:\n",
    "            total = sum(dictionary.values())\n",
    "            \n",
    "            print 'There are {} {} {}:'.format(total, p_or_g, i_or_t)\n",
    "            for interval_type in types:\n",
    "                print 'Number of type {}: {}'.format(interval_type+' '*(15-len(interval_type)),\\\n",
    "                                                     dictionary[interval_type])\n",
    "            print ''\n",
    "            \n",
    "        return\n",
    "    \n",
    "    print_result(count_pred, length_pred, count_gold, length_gold)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_phrase(tags_list, genia_tags_list, phrase='NP'):\n",
    "    filtered_tags_list = []\n",
    "    \n",
    "    for i in range(len(tags_list)):\n",
    "        tags = tags_list[i]\n",
    "        genia_tags = genia_tags_list[i]\n",
    "        \n",
    "        phrases = [x[3][2:] for x in genia_tags]\n",
    "        \n",
    "        filtered_tags = [tags[j] for j in range(len(tags)) if phrases[j] == phrase]\n",
    "        \n",
    "        filtered_tags_list.append(filtered_tags)\n",
    "    \n",
    "    return filtered_tags_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
