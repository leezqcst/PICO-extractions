{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF What's Wrong with Participants? --II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/envs/tensorflow/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Jing/anaconda/envs/tensorflow/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from crf import *\n",
    "from crf_support import get_all_data\n",
    "import sys,os,pickle\n",
    "\n",
    "import os, time, pprint\n",
    "\n",
    "from features_generator import abstracts2features, get_genia_tags, sanity_check\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = 'P'\n",
    "eval_tags = [tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get train data\n",
    "train_tokens, train_tags = get_all_data('train', tag)\n",
    "train_genia_tags = get_genia_tags('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get dev data\n",
    "dev_tokens, dev_tags = get_all_data('dev', tag)\n",
    "dev_genia_tags = get_genia_tags('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get test data\n",
    "test_tokens, test_tags = get_all_data('test', tag)\n",
    "test_genia_tags = get_genia_tags('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare bag of words in train and dev, and test\n",
    "\n",
    "def bagofwords(dat):\n",
    "    dat_set=set()\n",
    "    for abstract in dat:\n",
    "        dat_set.update(abstract)\n",
    "    return dat_set\n",
    "\n",
    "\n",
    "train_set = bagofwords(train_tokens)\n",
    "dev_set = bagofwords(dev_tokens)\n",
    "test_set = bagofwords(test_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.0001, 0.0001): [0.52634933593511524,\n",
       "  0.43697861157889167,\n",
       "  0.47715768242587625],\n",
       " (0.0001, 0.001): [0.55854056838367594,\n",
       "  0.44449206574046446,\n",
       "  0.49487034840599514],\n",
       " (0.0001, 0.01): [0.60911415766341093,\n",
       "  0.45603869820708953,\n",
       "  0.52143931607158778],\n",
       " (0.0001, 0.1): [0.68131797232957758,\n",
       "  0.46206041852235979,\n",
       "  0.55063603276601092],\n",
       " (0.0001, 1): [0.75078030989922828, 0.46865655460635064, 0.57696627029307224],\n",
       " (0.001, 0.0001): [0.54642052201828384,\n",
       "  0.43682664642721314,\n",
       "  0.48550355155305897],\n",
       " (0.001, 0.001): [0.55921956396949013,\n",
       "  0.44838277706991364,\n",
       "  0.49753169823310722],\n",
       " (0.001, 0.01): [0.61454398670159172,\n",
       "  0.45335926829725703,\n",
       "  0.52171860996215913],\n",
       " (0.001, 0.1): [0.68264718102813748, 0.4635564626920633, 0.55213785235848623],\n",
       " (0.001, 1): [0.75690910229299357, 0.46447865196054972, 0.57558528966335065],\n",
       " (0.01, 0.0001): [0.59386039484298236,\n",
       "  0.45955267946253187,\n",
       "  0.51803234679204246],\n",
       " (0.01, 0.001): [0.60655275609492665,\n",
       "  0.45538841751451431,\n",
       "  0.51992541944445925],\n",
       " (0.01, 0.01): [0.62719989572815038, 0.4614293291750482, 0.531649566720097],\n",
       " (0.01, 0.1): [0.6866779747836127, 0.46007116880368915, 0.55093861079320217],\n",
       " (0.01, 1): [0.75592777128782473, 0.46666965297944885, 0.57688448720854191],\n",
       " (0.1, 0.0001): [0.66978442635966151,\n",
       "  0.47944338875414005,\n",
       "  0.55881013023926573],\n",
       " (0.1, 0.001): [0.66396954242525952, 0.48207418966400634, 0.55854965913857046],\n",
       " (0.1, 0.01): [0.67706038651307909, 0.47990213976922619, 0.56165120140765856],\n",
       " (0.1, 0.1): [0.71106498397435391, 0.47664829928426872, 0.57059788420067992],\n",
       " (0.1, 1): [0.76080686793326435, 0.46424663226546226, 0.57660621250245825],\n",
       " (1, 0.0001): [0.75562605238209701, 0.48833541197931718, 0.59291979167542797],\n",
       " (1, 0.001): [0.75232800154351753, 0.49086301131524035, 0.59399947014146715],\n",
       " (1, 0.01): [0.755341285237773, 0.48950172625421334, 0.59399876979503496],\n",
       " (1, 0.1): [0.76171377391466144, 0.48125619912445528, 0.58950103298863965],\n",
       " (1, 1): [0.77239906429467153, 0.46868390968021267, 0.58325341504343053],\n",
       " ('l1_1', 'l2_0.001'): [0.7849944008958567,\n",
       "  0.5098645331393763,\n",
       "  0.6181998566940418],\n",
       " ('l1_1', 'l2_0.01'): [0.7873861247372109,\n",
       "  0.5107737067006092,\n",
       "  0.6196095731774568]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name='OneNegOneHot'\n",
    "file_name='crf_results/{}'.format(feature_name)\n",
    "f = open(file_name + '_results.txt','r')\n",
    "result=pickle.load(f)\n",
    "f.close()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22646 words in Dev data, and 7818 unseen words (34.5226530072)\n",
      "There are 14655 words in Test data, and 3895 unseen words (26.5779597407)\n"
     ]
    }
   ],
   "source": [
    "#count the words that are not in train dataset:\n",
    "\n",
    "dev_miss = 0\n",
    "for word in dev_set:\n",
    "    if word not in train_set:\n",
    "        dev_miss+=1\n",
    "\n",
    "test_miss=0\n",
    "for word in test_set:\n",
    "    if word not in train_set:\n",
    "        test_miss+=1\n",
    "\n",
    "        \n",
    "print \"There are %s words in Dev data, and %s unseen words (%s)\" %(len(dev_set),dev_miss,np.float(dev_miss)/len(dev_set)*100)\n",
    "print \"There are %s words in Test data, and %s unseen words (%s)\" %(len(test_set),test_miss,np.float(test_miss)/len(test_set)*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.7424930423319174, 0.48120372128346306, 0.5839525372962386)\n",
      "test:\n",
      "P: (0.7572129255626082, 0.5026333429091258, 0.6042014388489209)\n"
     ]
    }
   ],
   "source": [
    "# Predict dev tags\n",
    "pred_dev_tags = predict_tags(tagger, dev_features)\n",
    "\n",
    "#evaluate result of the words that have seen.\n",
    "\n",
    "def seen_words_pred(tokens, tags, pred_tags):\n",
    "    seen_tags =[]\n",
    "    seen_pred_tags=[]\n",
    "    for i,abstract in enumerate(tokens):\n",
    "        dev=[]\n",
    "        pred=[]\n",
    "        for j, word in enumerate(abstract):\n",
    "            if word in train_set:\n",
    "                dev.append(tags[i][j])\n",
    "                pred.append(pred_tags[i][j])\n",
    "        seen_tags.append(dev)\n",
    "        seen_pred_tags.append(pred)\n",
    "    return seen_tags, seen_pred_tags\n",
    "\n",
    "seen_dev_tags, seen_pred_dev_tags = seen_words_pred(dev_tokens,dev_tags,pred_dev_tags)\n",
    "# Evaluate dev tags\n",
    "dev_result = evaluate_prediction(seen_pred_dev_tags, seen_dev_tags, eval_tags)\n",
    "print 'dev:'\n",
    "print_result(dev_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict test tags\n",
    "pred_test_tags = predict_tags(tagger, test_features)\n",
    "\n",
    "seen_test_tags, seen_pred_test_tags = seen_words_pred(test_tokens,test_tags,pred_test_tags)\n",
    "\n",
    "# # Evaluate test tags\n",
    "test_result = evaluate_prediction(seen_pred_test_tags, seen_test_tags, eval_tags)\n",
    "print 'test:'\n",
    "print_result(test_result)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we limit to the words that have seen in the dataset, the F1 score is slightly better. Main problem is not unseen words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.746385029770343, 0.4764274726269116, 0.5816072908036454)\n",
      "train:\n",
      "P: (0.8331695473726805, 0.5432444656632409, 0.6576723882242891)\n",
      "test:\n",
      "P: (0.7552387740555951, 0.4816801527411583, 0.5882091706450538)\n"
     ]
    }
   ],
   "source": [
    "# result of the one neg one hot, no other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tested features that include features of the neghbors, overfitting, got worse result on predictions (0.07).\n",
    "\n",
    "2. Test Features with only the ones for the word itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.7288770053475936, 0.4933490181883992, 0.5884194053208137)\n",
      "train:\n",
      "P: (0.8203448339860062, 0.5553308038294343, 0.6623112942498595)\n",
      "test:\n",
      "P: (0.7284967320261438, 0.5066824256750614, 0.5976727974690332)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"One Negh with the word's features\n",
    "options_string = 'left_neighbors=1 right_neighbors=1 one_hot \\\n",
    "one_hot_neighbors inside_paren pos chunk iob named_entity isupper istitle'\n",
    "\n",
    "w2v=None\n",
    "\n",
    "features_name = 'Feat7OneNeg'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test Features with only the ones for the word itself, with w2v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.4004106776180698, 0.02646819292371731, 0.04965411874549081)\n",
      "train:\n",
      "P: (0.3377854373115037, 0.019699977385230043, 0.037228738306662235)\n",
      "test:\n",
      "P: (0.38258164852255055, 0.022365669606327847, 0.04226077993471912)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "options_string = 'left_neighbors=1 right_neighbors=1 w2v_model=pubmed w2v \\\n",
    "w2v_neighbors w2v_size=10 inside_paren pos chunk iob named_entity isupper istitle'\n",
    "\n",
    "w2v=True\n",
    "\n",
    "features_name = 'Feat7OneNegw2v'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test Features with word itself and neigbors, with one hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.7433616111455963, 0.48764817663559856, 0.5889456572224803)\n",
      "train:\n",
      "P: (0.866936073727326, 0.5956604769203708, 0.7061408081500126)\n",
      "test:\n",
      "P: (0.7543541869862059, 0.4922265660514592, 0.5957306338028169)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "options_string = 'left_neighbors=1 right_neighbors=1 one_hot \\\n",
    "one_hot_neighbors inside_paren_neighbors pos_neighbors chunk_neighbors iob_neighbors named_entity_neighbors \\\n",
    "chunk_end chunk_end_neighbors same_chunk_neighbors '\n",
    "\n",
    "w2v=True\n",
    "\n",
    "features_name = 'FeatAllOneNegFeatAll'\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set options\n",
    "big_options_string = 'left_neighbors=3 right_neighbors=3 inside_paren pos chunk iob named_entity \\\n",
    "inside_paren_neighbors pos_neighbors chunk_neighbors iob_neighbors named_entity_neighbors \\\n",
    "chunk_end chunk_end_neighbors same_chunk_neighbors \\\n",
    "one_hot one_hot_neighbors w2v_model=pubmed w2v w2v_neighbors w2v_size=10 cosine_simil cosine_simil_neighbors \\\n",
    "isupper isupper_neighbors istitle istitle_neighbors'\n",
    "\n",
    "options_string = 'left_neighbors=1 right_neighbors=1 one_hot \\\n",
    "one_hot_neighbors'\n",
    "\n",
    "w2v=False\n",
    "\n",
    "features_name = 'OneNeig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499: ['Pulsed', 'azithromycin', 'treatment']\n"
     ]
    }
   ],
   "source": [
    "# Compute features for train\n",
    "train_features = abstracts2features(train_tokens, train_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999: ['Serum', 'bactericidal', 'activities']\n"
     ]
    }
   ],
   "source": [
    "# Compute features for dev\n",
    "dev_features = abstracts2features(dev_tokens, dev_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500: ['Efficacy', 'and', 'cost-effectiveness']\n"
     ]
    }
   ],
   "source": [
    "# Compute features for test\n",
    "test_features = abstracts2features(test_tokens, test_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts: 3500\n",
      "Number of tokens:    927022\n",
      "Number of features:  2774066 \n",
      "\n",
      "Avg tokens per abstract: 264\n",
      "Avg features per token:  2 \n",
      "\n",
      "Max features per token:  3\n",
      "Min features per token:  2\n"
     ]
    }
   ],
   "source": [
    "# For debug\n",
    "sanity_check(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Run grid search\n",
    "# grid_file_name = 'crf_results/{}_grid'.format(features_name)\n",
    "# num_iters = 100\n",
    "# l1_list = [ 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "# l2_list = [ 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "# start_time = time.time()\n",
    "# grid_search_result = grid_search(train_features, train_tags, dev_features, dev_tags,\\\n",
    "#                                  num_iters, l1_list, l2_list, eval_tags, file_name=grid_file_name, save=True)\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# os.remove(grid_file_name + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort result\n",
    "# sorted_result = sort_by_metric(grid_search_result, tag, metric='f1')\n",
    "# print_result(sorted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set options\n",
    "num_iters = 100\n",
    "l1 = 1\n",
    "l2 = 0.1\n",
    "file_name = 'crf_results/{}'.format(features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "--- 40.0797998905 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run CRF\n",
    "start_time = time.time()\n",
    "crf_result = get_crf_results(train_features, train_tags, dev_features, dev_tags, num_iters, l1, l2, eval_tags,\n",
    "                             file_name=file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: (0.741732171942497, 0.4738937652701113, 0.5783066007785108)\n"
     ]
    }
   ],
   "source": [
    "# Print result\n",
    "print_result(crf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get model from file\n",
    "tagger = get_tagger(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "None   -> None    1.917295\n",
      "P      -> P       1.903707\n",
      "None   -> P       -1.233491\n",
      "P      -> None    -3.488813\n",
      "\n",
      "Top positive:\n",
      "6.386364 None   word[0]:BACKGROUND\n",
      "5.351200 None   word[0]:DESIGN\n",
      "4.951513 None   word[0]:PARTICIPANTS\n",
      "3.983060 None   word[1]:Eleven\n",
      "3.441205 None   word[0]:METHODS\n",
      "3.387782 None   word[1]:Nine\n",
      "3.344130 None   word[0]:.\n",
      "3.314683 None   word[0]:As\n",
      "3.270989 None   word[0]:Both\n",
      "3.260569 P      word[0]:alcoholics\n",
      "3.107455 None   word[0]:However\n",
      "3.074564 None   word[1]:Fifty-four\n",
      "3.015337 None   word[-1]:hypertension.\n",
      "2.921317 None   word[0]:PATIENTS\n",
      "2.884139 None   word[0]:PURPOSE\n",
      "2.835580 None   word[0]:Of\n",
      "2.809665 None   word[0]:Overall\n",
      "2.806916 None   word[0]:SUBJECTS\n",
      "2.727374 None   word[0]:Results\n",
      "2.699177 None   word[0]:In\n",
      "\n",
      "Top negative:\n",
      "-2.030994 None   word[1]:PURPOSE\n",
      "-2.035106 P      word[0]:treating\n",
      "-2.041772 P      word[0]:These\n",
      "-2.071515 None   word[1]:OBJECTIVE\n",
      "-2.151928 None   word[-1]:PARTICIPANTS\n",
      "-2.166695 P      word[-1]:volunteers.\n",
      "-2.181027 None   word[0]:students\n",
      "-2.182525 P      word[1]:Twenty\n",
      "-2.213121 P      word[0]:There\n",
      "-2.229077 P      word[0]:We\n",
      "-2.326133 P      word[0]:?\n",
      "-2.340726 P      word[0]:They\n",
      "-2.349522 P      word[0]:This\n",
      "-2.525368 P      word[0]:The\n",
      "-2.662365 P      word[0]:OBJECTIVE\n",
      "-2.699177 P      word[0]:In\n",
      "-2.835580 P      word[0]:Of\n",
      "-2.921317 P      word[0]:PATIENTS\n",
      "-3.344130 P      word[0]:.\n",
      "-3.441205 P      word[0]:METHODS\n"
     ]
    }
   ],
   "source": [
    "# For debug\n",
    "print_model_info(tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.741732171942497, 0.4738937652701113, 0.5783066007785108)\n",
      "train:\n",
      "P: (0.8218648286425426, 0.5393120084428474, 0.6512622891127564)\n",
      "test:\n",
      "P: (0.7573180931140229, 0.49395399581780164, 0.5979199911957299)\n"
     ]
    }
   ],
   "source": [
    "# Predict dev tags\n",
    "pred_dev_tags = predict_tags(tagger, dev_features)\n",
    "\n",
    "# Evaluate dev tags\n",
    "dev_result = evaluate_prediction(pred_dev_tags, dev_tags, eval_tags)\n",
    "print 'dev:'\n",
    "print_result(dev_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict train tags\n",
    "pred_train_tags = predict_tags(tagger, train_features)\n",
    "\n",
    "# Evaluate train tags\n",
    "train_result = evaluate_prediction(pred_train_tags, train_tags, eval_tags)\n",
    "print 'train:'\n",
    "print_result(train_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict test tags\n",
    "pred_test_tags = predict_tags(tagger, test_features)\n",
    "\n",
    "# Evaluate test tags\n",
    "test_result = evaluate_prediction(pred_test_tags, test_tags, eval_tags)\n",
    "print 'test:'\n",
    "print_result(test_result)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.7424930423319174, 0.48120372128346306, 0.5839525372962386)\n",
      "test:\n",
      "P: (0.7572129255626082, 0.5026333429091258, 0.6042014388489209)\n"
     ]
    }
   ],
   "source": [
    "# Predict dev tags\n",
    "pred_dev_tags = predict_tags(tagger, dev_features)\n",
    "\n",
    "#evaluate result of the words that have seen.\n",
    "\n",
    "def seen_words_pred(tokens, tags, pred_tags):\n",
    "    seen_tags =[]\n",
    "    seen_pred_tags=[]\n",
    "    for i,abstract in enumerate(tokens):\n",
    "        dev=[]\n",
    "        pred=[]\n",
    "        for j, word in enumerate(abstract):\n",
    "            if word in train_set:\n",
    "                dev.append(tags[i][j])\n",
    "                pred.append(pred_tags[i][j])\n",
    "        seen_tags.append(dev)\n",
    "        seen_pred_tags.append(pred)\n",
    "    return seen_tags, seen_pred_tags\n",
    "\n",
    "seen_dev_tags, seen_pred_dev_tags = seen_words_pred(dev_tokens,dev_tags,pred_dev_tags)\n",
    "# Evaluate dev tags\n",
    "dev_result = evaluate_prediction(seen_pred_dev_tags, seen_dev_tags, eval_tags)\n",
    "print 'dev:'\n",
    "print_result(dev_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict test tags\n",
    "pred_test_tags = predict_tags(tagger, test_features)\n",
    "\n",
    "seen_test_tags, seen_pred_test_tags = seen_words_pred(test_tokens,test_tags,pred_test_tags)\n",
    "\n",
    "# # Evaluate test tags\n",
    "test_result = evaluate_prediction(seen_pred_test_tags, seen_test_tags, eval_tags)\n",
    "print 'test:'\n",
    "print_result(test_result)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On fold 0\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 1\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 2\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 3\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 4\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "--- 162.671914816 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run K-fold\n",
    "kfold_file_name = 'crf_results/{}_kfold'.format(features_name)\n",
    "\n",
    "start_time = time.time()\n",
    "kfold_result = get_kfold_results(train_features, train_tags, num_iters, l1, l2, eval_tags,\\\n",
    "                                 file_name=kfold_file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "os.remove(kfold_file_name + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "P: (0.743448275862069, 0.4230492510955589, 0.5392471549460169)\n",
      "Fold 1\n",
      "P: (0.7338930105427567, 0.4609724691887915, 0.5662636990170602)\n",
      "Fold 2\n",
      "P: (0.712115031613298, 0.4341311781162574, 0.5394152408172724)\n",
      "Fold 3\n",
      "P: (0.7171599922615592, 0.4529569892473118, 0.5552310342245188)\n",
      "Fold 4\n",
      "P: (0.7343669781291714, 0.46014282956958114, 0.565778023890515)\n",
      "Average\n",
      "P: (0.72819665768177089, 0.44625054344350013, 0.5531870305790767)\n"
     ]
    }
   ],
   "source": [
    "# Print all results\n",
    "print_result(kfold_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_with_spaces(l, spaces):\n",
    "    # This pads strings to be of space length and aligned left\n",
    "    formatter = lambda space: '{:' + str(space) + '}'\n",
    "    \n",
    "    for sublist in l:\n",
    "        print ''.join([formatter(space).format(string) for string, space in zip(sublist, spaces)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netilmicin               None None \n",
      "in                       P    None \n",
      "the                      P    None \n",
      "neonate                  P    None \n",
      ":                        None None \n",
      "pharmacokinetic          None None \n",
      "analysis                 None None \n",
      "and                      None None \n",
      "influence                None None \n",
      "of                       None None \n",
      "parenteral               None None \n",
      "nutrition                None None \n",
      ".                        None None \n",
      "OBJECTIVE                None None \n",
      "The                      None None \n",
      "aim                      None None \n",
      "of                       None None \n",
      "this                     None None \n",
      "study                    None None \n",
      "was                      None None \n",
      "to                       None None \n",
      "investigate              None None \n",
      "the                      None None \n",
      "impact                   None None \n",
      "of                       None None \n",
      "parenteral               None None \n",
      "nutrition                None None \n",
      "on                       None None \n",
      "netilmicin               None None \n",
      "pharmacokinetics         None None \n",
      "in                       None None \n",
      "critically               P    P    \n",
      "ill                      P    P    \n",
      "neonates                 P    P    \n",
      "during                   P    P    \n",
      "the                      P    P    \n",
      "first                    P    P    \n",
      "week                     P    P    \n",
      "of                       P    P    \n",
      "life                     P    P    \n",
      ".                        None None \n",
      "METHOD                   None None \n",
      "A                        None None \n",
      "total                    None None \n",
      "of                       None None \n",
      "200                      P    None \n",
      "neonates                 P    None \n",
      "(                        P    None \n",
      "gestational              P    None \n",
      "ages                     P    None \n",
      "26.4-41                  P    None \n",
      "weeks                    P    None \n",
      ")                        P    None \n",
      "treated                  P    None \n",
      "with                     P    None \n",
      "netilmicin               P    None \n",
      "(                        P    None \n",
      "4-5                      P    None \n",
      "mg/kg                    P    None \n",
      "in                       P    None \n",
      "extended                 P    None \n",
      "dosing                   P    None \n",
      "intervals                P    None \n",
      ")                        P    None \n",
      "for                      P    None \n",
      "postnatal                P    None \n",
      "sepsis                   P    None \n",
      "in                       P    None \n",
      "the                      P    None \n",
      "first                    P    None \n",
      "week                     P    None \n",
      "of                       P    None \n",
      "life                     P    None \n",
      "received                 None None \n",
      "either                   None None \n",
      "fluid                    None None \n",
      "therapy                  None None \n",
      "or                       None None \n",
      "parenteral               None None \n",
      "nutrition.               None None \n",
      "Netilmicin               None None \n",
      "peak                     None None \n",
      "and                      None None \n",
      "trough                   None None \n",
      "serum                    None None \n",
      "concentrations           None None \n",
      "were                     None None \n",
      "monitored                None None \n",
      "and                      None None \n",
      "netilmicin               None None \n",
      "pharmacokinetic          None None \n",
      "parameters               None None \n",
      "were                     None None \n",
      "compared                 None None \n",
      "with                     None None \n",
      "and                      None None \n",
      "without                  None None \n",
      "parenteral               None None \n",
      "nutrition                None None \n",
      ".                        None None \n",
      "RESULTS                  None None \n",
      "There                    None None \n",
      "were                     None None \n",
      "no                       None None \n",
      "statistically            None None \n",
      "significant              None None \n",
      "differences              None None \n",
      "between                  None None \n",
      "the                      None None \n",
      "pharmacokinetic          None None \n",
      "parameters               None None \n",
      "of                       None None \n",
      "netilmicin               None None \n",
      "(                        None None \n",
      "volume                   None None \n",
      "of                       None None \n",
      "distribution             None None \n",
      ",                        None None \n",
      "elimination              None None \n",
      "half-life                None None \n",
      ",                        None None \n",
      "clearance                None None \n",
      ")                        None None \n",
      "in                       None None \n",
      "critically               P    P    \n",
      "ill                      P    P    \n",
      "neonates                 P    P    \n",
      ">                        P    P    \n",
      "32                       P    P    \n",
      "weeks                    P    P    \n",
      "during                   P    None \n",
      "the                      P    None \n",
      "first                    P    None \n",
      "week                     P    None \n",
      "of                       P    None \n",
      "life                     P    None \n",
      "that                     None None \n",
      "received                 None None \n",
      "either                   None None \n",
      "fluid                    None None \n",
      "therapy                  None None \n",
      "or                       None None \n",
      "parenteral               None None \n",
      "nutrition.               None None \n",
      "For                      None None \n",
      "neonates                 P    None \n",
      "<                        P    None \n",
      "32                       P    None \n",
      "weeks                    P    None \n",
      "this                     None None \n",
      "comparison               None None \n",
      "was                      None None \n",
      "not                      None None \n",
      "feasible                 None None \n",
      "as                       None None \n",
      "the                      None None \n",
      "majority                 None None \n",
      "were                     None None \n",
      "parenterally             None None \n",
      "fed                      None None \n",
      ".                        None None \n",
      "CONCLUSION               None None \n",
      "Provision                None None \n",
      "of                       None None \n",
      "parenteral               None None \n",
      "nutrition                None None \n",
      "(                        None None \n",
      "versus                   None None \n",
      "fluid                    None None \n",
      "therapy                  None None \n",
      ")                        None None \n",
      "in                       None None \n",
      "critically               P    P    \n",
      "ill                      P    P    \n",
      "neonates                 P    P    \n",
      ">                        P    P    \n",
      "32                       P    P    \n",
      "weeks                    P    P    \n",
      "did                      None None \n",
      "not                      None None \n",
      "significantly            None None \n",
      "affect                   None None \n",
      "netilmicin               None None \n",
      "pharmacokinetics         None None \n",
      "and                      None None \n",
      "therefore                None None \n",
      "does                     None None \n",
      "not                      None None \n",
      "require                  None None \n",
      "modification             None None \n",
      "of                       None None \n",
      "recommended              None None \n",
      "netilmicin               None None \n",
      "dosage                   None None \n",
      "regimens                 None None \n",
      ".                        None None \n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "print_with_spaces(zip(dev_tokens[i], dev_tags[i], pred_dev_tags[i]), [25, 5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
