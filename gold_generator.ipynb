{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Run this first. This aggregates human annotations\n",
    "and generates gold annotations.\n",
    "\n",
    "Old version that uses union of all phrases.\n",
    "'''\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directory for annotations\n",
    "directory = 'PICO-annotations/batch5k'\n",
    "\n",
    "# Minimum number of count that a phrase must have\n",
    "# to be included in the gold annotations\n",
    "threshold = 3\n",
    "\n",
    "# Suffixes for the generated files\n",
    "machine_suffix = '_gold.ann'\n",
    "human_suffix = '_gold_human_readable.ann'\n",
    "\n",
    "tokens_suffix = '_tokens.txt'\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# For each subdirectory\n",
    "for subdir in os.listdir(directory):\n",
    "    subdir_path = directory + '/' + subdir\n",
    "    \n",
    "    # Not a directory\n",
    "    if not os.path.isdir(subdir_path):\n",
    "        continue\n",
    "    \n",
    "    # For each abstract in subdirectory\n",
    "    for abstract in os.listdir(subdir_path):\n",
    "        if abstract[-4:] == '.txt' and (not abstract[-10:] == tokens_suffix):\n",
    "            abstract_index = abstract[:-4]\n",
    "            \n",
    "            '''Step 1: Gather all annotations'''\n",
    "            \n",
    "            # This stores entries of the form\n",
    "            # ('Participants', [[34, 65], [344, 375], ...])\n",
    "            # [34, 65] means a Participants phrase starting at 34 and ending at 65\n",
    "            dictionary = defaultdict(list)\n",
    "            \n",
    "            # Go through each associated annotation\n",
    "            for annotation in os.listdir(subdir_path):\n",
    "                # Don't include our gold annotations!\n",
    "                if annotation[-4:] == '.ann' and annotation.startswith(abstract_index) \\\n",
    "                and machine_suffix not in annotation and human_suffix not in annotation:\n",
    "                    f = open(subdir_path + '/' + annotation)\n",
    "                    \n",
    "                    # Read each line\n",
    "                    for line in f.readlines():\n",
    "                        tokens = line.split()\n",
    "                        \n",
    "                        # This is e.g. 'Participants'\n",
    "                        pico_type = tokens[1]\n",
    "                        \n",
    "                        # Sometimes this comes up. It does not provide pico tags so we skip it.\n",
    "                        if pico_type == 'AnnotatorNotes':\n",
    "                            continue\n",
    "                        \n",
    "                        # Bad formatting that comes up\n",
    "                        if ';' in tokens[3]:\n",
    "                            continue\n",
    "                        \n",
    "                        # Start and end of this phrase\n",
    "                        start = int(tokens[2])\n",
    "                        end = int(tokens[3])\n",
    "                        \n",
    "                        dictionary[pico_type].append([start, end])\n",
    "                    \n",
    "                    f.close()\n",
    "            \n",
    "            # Sort each list in dictionary according to start values\n",
    "            for instance_list in dictionary.values():\n",
    "                instance_list.sort(key=lambda x: x[0])\n",
    "            \n",
    "            if DEBUG:\n",
    "                if abstract_index == '19931151':\n",
    "                    print dictionary\n",
    "            \n",
    "            '''Step 2: Aggregate the annotations'''\n",
    "            \n",
    "            # Build an aggregate dictionary\n",
    "            # by combining all [start, end] pairs that overlap\n",
    "            # into the same \"interval\" and count the number of overlapped pairs\n",
    "            # Format: ('Participants', [[20, 120, 3], [143, 165, 2], ...])\n",
    "            # [20, 120, 3] means an interval starting at 20 and ending at 120\n",
    "            # which is built from combining 3 different phrases\n",
    "            aggregate_dict = defaultdict(list)\n",
    "            \n",
    "            for pico_type, instance_list in dictionary.iteritems():\n",
    "                # Keep track of the start and end of current interval,\n",
    "                # and the number of phrases the interval is made up of\n",
    "                curr_start = None\n",
    "                curr_end = None\n",
    "                num_phrases = 0\n",
    "                \n",
    "                for start, end in instance_list:\n",
    "                    if num_phrases == 0:\n",
    "                        # There is no current interval\n",
    "                        curr_start = start\n",
    "                        curr_end = end\n",
    "                        num_phrases = 1\n",
    "                    elif start < curr_end:\n",
    "                        # This phrase overlaps with the current interval,\n",
    "                        # so update the current interval.\n",
    "                        curr_end = max(curr_end, end)\n",
    "                        num_phrases += 1\n",
    "                    else:\n",
    "                        # This phrase does not overlap with the current interval,\n",
    "                        # so store the current inverval and start over.\n",
    "                        if num_phrases >= threshold:\n",
    "                            aggregate_dict[pico_type].append([curr_start, curr_end, num_phrases])\n",
    "                        \n",
    "                        curr_start = start\n",
    "                        curr_end = end\n",
    "                        num_phrases = 1\n",
    "                \n",
    "                # Store the last interval\n",
    "                if num_phrases >= threshold:\n",
    "                    aggregate_dict[pico_type].append([curr_start, curr_end, num_phrases])\n",
    "            \n",
    "            if DEBUG:\n",
    "                if abstract_index == '19931151':\n",
    "                    print aggregate_dict\n",
    "                    \n",
    "            '''Step 3: Write out results'''\n",
    "            \n",
    "            # Write gold annotations for system input\n",
    "            # Format: Participants 20 120 345 678 ...\n",
    "            f = open(subdir_path + '/' + abstract_index + machine_suffix, 'w')\n",
    "            \n",
    "            for pico_type, instance_list in aggregate_dict.iteritems():\n",
    "                f.write(pico_type + ' ')\n",
    "                \n",
    "                for start, end, num_phrases in instance_list:\n",
    "                    f.write(str(start) + ' ' + str(end) + ' ')\n",
    "                \n",
    "                f.write('\\n')\n",
    "            \n",
    "            f.close()\n",
    "            \n",
    "            # Now write a human readable one\n",
    "            # Format: Participants [start] [end] [num_phrases]\n",
    "            # [corresponding text]\n",
    "            \n",
    "            # First get the abstract text\n",
    "            abstract_file = open(subdir_path + '/' + abstract)\n",
    "            abstract_text = abstract_file.read()\n",
    "            abstract_file.close()\n",
    "            \n",
    "            f = open(subdir_path + '/' + abstract_index + human_suffix, 'w')\n",
    "            \n",
    "            for pico_type, instance_list in aggregate_dict.iteritems():\n",
    "                for start, end, num_phrases in instance_list:\n",
    "                    f.write(pico_type + ' ')\n",
    "                    f.write(str(start) + ' ' + str(end) + ' ' + str(num_phrases))\n",
    "                    f.write('\\n')\n",
    "                    \n",
    "                    f.write(abstract_text[start:end])\n",
    "                    f.write('\\n')\n",
    "            \n",
    "            f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
