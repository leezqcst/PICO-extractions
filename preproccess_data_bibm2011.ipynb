{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import lxml\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_and_write_good_abstracts():\n",
    "    directory = 'bibm2011corpus-master'\n",
    "\n",
    "    good_abstracts_list = []\n",
    "\n",
    "    # For each subdirectory\n",
    "    for subdir in os.listdir(directory):\n",
    "        subdir_path = directory + '/' + subdir\n",
    "        ann_subdir_path = directory + '/' + subdir\n",
    "        # print subdir_path\n",
    "\n",
    "        # Not a directory\n",
    "        if not os.path.isdir(subdir_path):\n",
    "            continue\n",
    "\n",
    "        # For each abstract in subdirectory\n",
    "        for abstract in os.listdir(subdir_path):\n",
    "            if (abstract.endswith('.xml')):\n",
    "                abstract_path = subdir_path + '/' + abstract; \n",
    "                \n",
    "                full_text_txt_path = abstract_path[:-4] + '.txt';\n",
    "                f = open(full_text_txt_path, 'w')\n",
    "                \n",
    "                soup = BeautifulSoup(open(abstract_path).read())\n",
    "                pmid = soup.find(\"abstract\")['id']\n",
    "\n",
    "                sentences = list(soup.findAll(\"s\"))\n",
    "                sentances_part = soup.find_all(section=\"participants\");\n",
    "                fulltext = soup.find('fulltext')\n",
    "                if (fulltext.string == None):\n",
    "                    print \"DAMN\"\n",
    "                else:\n",
    "                    out = str(fulltext.string)\n",
    "                    f.write(out)\n",
    "                \n",
    "                f.close()\n",
    "                \n",
    "                use_abstract = True;\n",
    "\n",
    "                for i in sentances_part:\n",
    "                    if i.string == None:\n",
    "                        use_abstract = False;\n",
    "\n",
    "                if use_abstract:\n",
    "                    good_abstracts_list.append(abstract_path)\n",
    "#                     good_abstracts_list = good_abstracts_list + abstract_path + '\\n'\n",
    "    \n",
    "#     shuffle(good_abstracts_list)\n",
    "    \n",
    "#     output_list = ''\n",
    "#     for item in good_abstracts_list:\n",
    "#         output_list = output_list + item + '\\n'\n",
    "    \n",
    "#     f = open('./bibm2011corpus-master/abstracts_1.txt', 'w')\n",
    "#     f.write(output_list)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_and_write_good_abstracts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./bibm2011corpus-master/abstracts_1.txt', 'r')\n",
    "abstract_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstract_list = [x.strip() for x in abstract_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_abstract(abstract_path):\n",
    "    soup = BeautifulSoup(open(abstract_path).read())\n",
    "    pmid = soup.find(\"abstract\")['id']\n",
    "\n",
    "    sentences = list(soup.findAll(\"s\"))\n",
    "    sentances_part = soup.find_all(section=\"participants\");\n",
    "    \n",
    "    full_text = str(soup.find(\"fulltext\").string)\n",
    "    \n",
    "    participant_phrase = str(sentances_part[0].string)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print \"original part phrase: \", participant_phrase\n",
    "    print \"\"\n",
    "    print str(sentances_part[1].string)\n",
    "    index = full_text.find(participant_phrase)\n",
    "    print \"INDEX: \", index\n",
    "    print full_text[index:(index+len(participant_phrase))]\n",
    "    print \"\"\n",
    "    index2 = full_text.find(str(sentances_part[1].string))\n",
    "    print \"INDEX2: \", index2\n",
    "    print full_text[index2:(index2+(len(str(sentances_part[1].string))))]\n",
    "    print \"\"\n",
    "    print full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_in_interval(start, end):\n",
    "    f = open('./bibm2011corpus-master/abstracts_1.txt', 'r')\n",
    "    abstract_list = f.readlines()\n",
    "    abstract_list = [x.strip() for x in abstract_list]\n",
    "    final_list = abstract_list[start:end]\n",
    "    \n",
    "    process_abstract(abstract_list[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "a = 'hello my name is hansa'\n",
    "print a[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original part phrase:  130 volunteers (81 men) recruited on an opportunistic basis.\n",
      "\n",
      "Exclusion criteria included age under 18 , trained health professionals , and cardiopulmonary resuscitation ( CPR ) training within the past 3 months .\n",
      "INDEX:  290\n",
      "130 volunteers (81 men) recruited on an opportunistic basis.\n",
      "\n",
      "INDEX2:  -1\n",
      "\n",
      "\n",
      "OBJECTIVES: To determine whether listening to music during cardiopulmonary resuscitation (CPR) training increases the proportion of lay people delivering chest compressions of 100 per minute. \r\n",
      "DESIGN: Prospective randomised crossover trial. \r\n",
      "SETTING: Large UK university. \r\n",
      "PARTICIPANTS: 130 volunteers (81 men) recruited on an opportunistic basis. \r\n",
      "Exclusion criteria included age under 18, trained health professionals, and cardiopulmonary resuscitation (CPR) training within the past three months. \r\n",
      "INTERVENTIONS: Volunteers performed three sequences of one minute of continuous chest compressions on a skill meter resuscitation manikin accompanied by no music, repeated choruses of Nellie the Elephant (Nellie), and That's the Way (I like it) (TTW) according to a pre-randomised order. \r\n",
      "MAIN OUTCOME MEASURES: Rate of chest compressions delivered (primary outcome), depth of compressions, proportion of incorrect compressions, and type of error. \r\n",
      "RESULTS: Median (interquartile range) compression rates were 110 (93-119) with no music, 105 (98-107) with Nellie, and 109 (103-110) with TTW. \r\n",
      "There were significant differences within groups between Nellie v no music and Nellie v TTW (P<0.001) but not no music v TTW (P=0.055). \r\n",
      "A compression rate of between 95 and 105 was achieved with no music, Nellie, and TTW for 15/130 (12%), 42/130 (32%), and 12/130 (9%) attempts, respectively. \r\n",
      "Differences in proportions were significant for Nellie v no music and Nellie v TTW (P<0.001) but not for no music v TTW (P=0.55). \r\n",
      "Relative risk for a compression rate between 95 and 105 was 2.8 (95% confidence interval 1.66 to 4.80) for Nellie v no music, 0.8 (0.40 to 1.62) for TTW v no music, and 3.5 (1.97 to 6.33) for Nellie v TTW. \r\n",
      "The number needed to treat for listening to Nellie v no music was 5 (4 to 10)-that is, the number of cardiac arrests required during which lay responders listen to Nellie to facilitate one patient receiving compressions at the correct rate (v no music) would be between four and 10. \r\n",
      "A greater proportion of compressions were too shallow when participants listened to Nellie v no music (56% v 47%, P=0.022). \r\n",
      "CONCLUSIONS: Listening to Nellie the Elephant significantly increased the proportion of lay people delivering compression rates at close to 100 per minute. \r\n",
      "Unfortunately it also increased the proportion of compressions delivered at an inadequate depth. \r\n",
      "As current resuscitation guidelines give equal emphasis to correct rate and depth, listening to Nellie the Elephant as a learning aid during CPR training should be discontinued. \r\n",
      "Further research is required to identify music that, when played during CPR training, increases the proportion of lay responders providing chest compressions at both the correct rate and depth.\n"
     ]
    }
   ],
   "source": [
    "get_data_in_interval(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_data()\n",
    "for abstract_path in abstract_list:\n",
    "    soup = BeautifulSoup(open(abstract_path).read())\n",
    "    pmid = soup.find(\"abstract\")['id']\n",
    "\n",
    "    sentences = list(soup.findAll(\"s\"))\n",
    "    sentances_part = soup.find_all(section=\"participants\");\n",
    "\n",
    "    for i in sentances_part:\n",
    "        if i.string == None:\n",
    "            print \"FUCK\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
