{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from genia_features_2 import abstracts2features\n",
    "from preprocess_data import get_all_data_train # for testing\n",
    "from preprocess_data import get_all_data\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_array, tag_array = get_all_data(sentences=True)\n",
    "# word_array[0] = [[\"this\", \"is\", \"sentence\", \"1\"], [\"this, \"is\", \"2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Null_TAG = 'None'\n",
    "P_TAG = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform X to sparse matrices \n",
    "def x_dict_to_vect(X, dict_vect=None):\n",
    "    x_vect = []\n",
    "    if dict_vect is None: # dict_vect is None => fit dict_vect\n",
    "        x_flat = [word for abstract in X for word in abstract]\n",
    "        dict_vect = DictVectorizer()\n",
    "        dict_vect.fit(x_flat)\n",
    "    print dict_vect.transform(X[0])\n",
    "    x_vect = [dict_vect.transform(abstract) for abstract in X]\n",
    "    return x_vect, dict_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # TESTING CODE #\n",
    "# word_array, tag_array = get_all_data_train()\n",
    "# X,Y = abstracts2features(word_array[1:10],tag_array[1:10],1,1,False, w2v_size=100)\n",
    "# x_vect, dict_vect = x_dict_to_vect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_placeholder = tf.placeholder(tf.float32, name='data_placeholder')\n",
    "# labels_placeholder = tf.placeholder(tf.float32, name='labels_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feed_dict_train = {data_placeholder: x_vect, labels_placeholder : Y}\n",
    "# # Run the optimizer, get the loss, get the predictions.\n",
    "# # We can run multiple things at once and get their outputs\n",
    "# _, loss_value_train, predictions_value_train, accuracy_value_train = session.run(feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_1_hot_abstract_encodings(word_array, tag_array):\n",
    "    max_abstract_len = max([len(x) for x in word_array])\n",
    "#     print max_abstract_len\n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor(max_abstract_len)\n",
    "    abstract_array = [' '.join(x) for x in word_array]\n",
    "    X = np.array(list(vocab_processor.fit_transform(abstract_array)))\n",
    "\n",
    "    Y = []\n",
    "    for arr in tag_array:\n",
    "        y_abs = [0 if x==Null_TAG else 1 for x in arr]\n",
    "        if (len(y_abs) < max_abstract_len):\n",
    "            num_padding = max_abstract_len - len(y_abs)\n",
    "            y_abs.extend(([0]*num_padding))\n",
    "        Y.append(np.array(y_abs))\n",
    "    \n",
    "    Y = np.array(Y)\n",
    "        # return X, Y\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_1_hot_sentence_encodings(word_array, tag_array):\n",
    "    word_array_sentences = [sentence for abstract in word_array for sentence in abstract]\n",
    "#     print word_array_sentences[2]\n",
    "    tag_array_sentences = [sentence for abstract in tag_array for sentence in abstract]\n",
    "    (X, Y) = get_1_hot_abstract_encodings(word_array_sentences,tag_array_sentences)\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # word_array[0] is a list of words in single abstract \n",
    "# # n = number of words on either side of target word\n",
    "# def get_1_hot_surround_n_encodings(word_array, tag_array, n):\n",
    "#     # create array of arrays with 2n*1 words \n",
    "#     word_array_context = []\n",
    "    \n",
    "#     for abstract in word_array:\n",
    "#         # pad abstract with * \n",
    "#         padding = [\"*\"] * n\n",
    "#         padded_abstract = padding\n",
    "#         padded_abstract.extend(abstract)\n",
    "#         padded_abstract.extend(padding)\n",
    "#         # for all words (excluding padding)\n",
    "#         for i in range(n, len(abstract)-n):\n",
    "#             word_array_context.extend(i-n,i+n)\n",
    "            \n",
    "#     tags = [y for x in tag_array for y in x] # flatten tag array \n",
    "#     (X, Y) = get_1_hot_abstract_encodings(word_array_context, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_array, tag_array = get_all_data_train(sentences=True)\n",
    "# X, Y = get_1_hot_sentence_encodings(word_array, tag_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_array, tag_array = get_all_data(sentences=False)\n",
    "# print word_array[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# abstract_array = [' '.join(x) for x in word_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print abstract_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
