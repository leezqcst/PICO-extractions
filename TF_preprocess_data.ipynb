{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from genia_features_2 import abstracts2features\n",
    "from preprocess_data import get_all_data_train # for testing\n",
    "from preprocess_data import get_all_data\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_array, tag_array = get_all_data(sentences=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Null_TAG = 'None'\n",
    "P_TAG = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform X to sparse matrices \n",
    "def x_dict_to_vect(X, dict_vect=None):\n",
    "    x_vect = []\n",
    "    if dict_vect is None: # dict_vect is None => fit dict_vect\n",
    "        x_flat = [word for abstract in X for word in abstract]\n",
    "        dict_vect = DictVectorizer()\n",
    "        dict_vect.fit(x_flat)\n",
    "    print dict_vect.transform(X[0])\n",
    "    x_vect = [dict_vect.transform(abstract) for abstract in X]\n",
    "    return x_vect, dict_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abstracts2features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4894f4801e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TESTING CODE #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mword_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_data_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabstracts2features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_dict_to_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abstracts2features' is not defined"
     ]
    }
   ],
   "source": [
    "# # TESTING CODE #\n",
    "# word_array, tag_array = get_all_data_train()\n",
    "# X,Y = abstracts2features(word_array[1:10],tag_array[1:10],1,1,False, w2v_size=100)\n",
    "# x_vect, dict_vect = x_dict_to_vect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_placeholder = tf.placeholder(tf.float32, name='data_placeholder')\n",
    "# labels_placeholder = tf.placeholder(tf.float32, name='labels_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feed_dict_train = {data_placeholder: x_vect, labels_placeholder : Y}\n",
    "# # Run the optimizer, get the loss, get the predictions.\n",
    "# # We can run multiple things at once and get their outputs\n",
    "# _, loss_value_train, predictions_value_train, accuracy_value_train = session.run(feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_1_hot_abstract_encodings(word_array, tag_array):\n",
    "    max_abstract_len = max([len(x) for x in word_array])\n",
    "#     print max_abstract_len\n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor(max_abstract_len)\n",
    "    abstract_array = [' '.join(x) for x in word_array]\n",
    "    X = np.array(list(vocab_processor.fit_transform(abstract_array)))\n",
    "\n",
    "    Y = []\n",
    "    for arr in tag_array:\n",
    "        y_abs = [0 if x==Null_TAG else 1 for x in arr]\n",
    "        if (len(y_abs) < max_abstract_len):\n",
    "            num_padding = max_abstract_len - len(y_abs)\n",
    "            y_abs.extend(([0]*num_padding))\n",
    "        Y.append(np.array(y_abs))\n",
    "    \n",
    "    Y = np.array(Y)\n",
    "        # return X, Y\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_1_hot_sentence_encodings(word_array, tag_array):\n",
    "    word_array_sentences = [sentence for abstract in word_array for sentence in abstract]\n",
    "    tag_array_sentences = [sentence for abstract in tag_array for sentence in abstract]\n",
    "    (X, Y) = get_1_hot_abstract_encodings(word_array_sentences,tag_array_sentences)\n",
    "    return (X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
