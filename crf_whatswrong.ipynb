{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF What's Wrong with Participants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from crf import *\n",
    "from crf_support import get_all_data, compare_tags, filter_phrase\n",
    "\n",
    "import os, time\n",
    "\n",
    "from features_generator import abstracts2features, get_genia_tags, sanity_check\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = 'P'\n",
    "eval_tags = [tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get train data\n",
    "train_tokens, train_tags = get_all_data('train', tag)\n",
    "train_genia_tags = get_genia_tags('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get dev data\n",
    "dev_tokens, dev_tags = get_all_data('dev', tag)\n",
    "dev_genia_tags = get_genia_tags('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get test data\n",
    "test_tokens, test_tags = get_all_data('test', tag)\n",
    "test_genia_tags = get_genia_tags('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pubmed_w2v_name = 'PubMed-w2v.bin'\n",
    "pubmed_w2v = Word2Vec.load_word2vec_format(pubmed_w2v_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pubmed_wiki_w2v_name = 'wikipedia-pubmed-and-PMC-w2v.bin'\n",
    "pubmed_wiki_w2v = Word2Vec.load_word2vec_format(pubmed_wiki_w2v_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set options\n",
    "big_options_string = 'left_neighbors=3 right_neighbors=3 inside_paren pos chunk iob named_entity \\\n",
    "inside_paren_neighbors pos_neighbors chunk_neighbors iob_neighbors named_entity_neighbors \\\n",
    "chunk_end chunk_end_neighbors same_chunk_neighbors \\\n",
    "one_hot one_hot_neighbors w2v_model=pubmed w2v w2v_neighbors w2v_size=10 cosine_simil cosine_simil_neighbors \\\n",
    "isupper isupper_neighbors istitle istitle_neighbors'\n",
    "\n",
    "options_string = 'left_neighbors=3 right_neighbors=3 one_hot one_hot_neighbors \\\n",
    "inside_paren pos chunk iob named_entity \\\n",
    "inside_paren_neighbors pos_neighbors chunk_neighbors iob_neighbors named_entity_neighbors \\\n",
    "chunk_end chunk_end_neighbors same_chunk_neighbors \\\n",
    "w2v_model=pubmed_wiki w2v w2v_neighbors w2v_size=30 \\\n",
    "cosine_simil cosine_simil_neighbors \\\n",
    "isupper isupper_neighbors istitle istitle_neighbors'\n",
    "\n",
    "w2v=pubmed_wiki_w2v\n",
    "\n",
    "features_name = 'P8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute features for train\n",
    "train_features = abstracts2features(train_tokens, train_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute features for dev\n",
    "dev_features = abstracts2features(dev_tokens, dev_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute features for test\n",
    "test_features = abstracts2features(test_tokens, test_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For debug\n",
    "sanity_check(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run grid search\n",
    "grid_file_name = 'crf_results/{}_grid'.format(features_name)\n",
    "num_iters = 200\n",
    "l1_list = [0.01, 0.1, 1]\n",
    "l2_list = [0.01, 0.1, 1]\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_result = grid_search(train_features, train_tags, dev_features, dev_tags,\\\n",
    "                                 num_iters, l1_list, l2_list, eval_tags, file_name=grid_file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "os.remove(grid_file_name + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort result\n",
    "sorted_result = sort_by_metric(grid_search_result, tag, metric='f1')\n",
    "print_result(sorted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set options\n",
    "num_iters = 200\n",
    "l1 = 1\n",
    "l2 = 0.01\n",
    "file_name = 'crf_results/{}'.format(features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run CRF\n",
    "start_time = time.time()\n",
    "crf_result = get_crf_results(train_features, train_tags, dev_features, dev_tags, num_iters, l1, l2, eval_tags,\n",
    "                             file_name=file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print result\n",
    "print_result(crf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get model from file\n",
    "tagger = get_tagger(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For debug\n",
    "print_model_info(tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict dev tags\n",
    "pred_dev_tags = predict_tags(tagger, dev_features)\n",
    "\n",
    "# Evaluate dev tags\n",
    "dev_result = evaluate_prediction(pred_dev_tags, dev_tags, eval_tags)\n",
    "print 'dev:'\n",
    "print_result(dev_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict train tags\n",
    "pred_train_tags = predict_tags(tagger, train_features)\n",
    "\n",
    "# Evaluate train tags\n",
    "train_result = evaluate_prediction(pred_train_tags, train_tags, eval_tags)\n",
    "print 'train:'\n",
    "print_result(train_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict test tags\n",
    "pred_test_tags = predict_tags(tagger, test_features)\n",
    "\n",
    "# Evaluate test tags\n",
    "test_result = evaluate_prediction(pred_test_tags, test_tags, eval_tags)\n",
    "print 'test:'\n",
    "print_result(test_result)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_result(pred_train_tags, file_name + '_pred_train_tags')\n",
    "write_result(pred_dev_tags, file_name + '_pred_dev_tags')\n",
    "write_result(pred_test_tags, file_name + '_pred_test_tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run K-fold\n",
    "kfold_file_name = 'crf_results/{}_kfold'.format(features_name)\n",
    "\n",
    "start_time = time.time()\n",
    "kfold_result = get_kfold_results(train_features, train_tags, num_iters, l1, l2, eval_tags,\\\n",
    "                                 file_name=kfold_file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "os.remove(kfold_file_name + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print all results\n",
    "print_result(kfold_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a sample prediction for an abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_with_spaces(l, spaces):\n",
    "    # This pads strings to be of space length and aligned left\n",
    "    formatter = lambda space: '{:' + str(space) + '}'\n",
    "    \n",
    "    for sublist in l:\n",
    "        print ''.join([formatter(space).format(string) for string, space in zip(sublist, spaces)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 300\n",
    "print_with_spaces(zip(dev_tokens[i], dev_tags[i], pred_dev_tags[i]), [25, 5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_tags(pred_dev_tags, dev_tags, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict evaluation to noun phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate dev tags\n",
    "dev_result = evaluate_prediction(filter_phrase(pred_dev_tags, dev_genia_tags),\\\n",
    "                                 filter_phrase(dev_tags, dev_genia_tags),\\\n",
    "                                 eval_tags)\n",
    "print 'dev:'\n",
    "print_result(dev_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Evaluate train tags\n",
    "train_result = evaluate_prediction(filter_phrase(pred_train_tags, train_genia_tags),\\\n",
    "                                   filter_phrase(train_tags, train_genia_tags),\\\n",
    "                                   eval_tags)\n",
    "print 'train:'\n",
    "print_result(train_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Evaluate test tags\n",
    "test_result = evaluate_prediction(filter_phrase(pred_test_tags, test_genia_tags),\\\n",
    "                                  filter_phrase(test_tags, test_genia_tags),\\\n",
    "                                  eval_tags)\n",
    "print 'test:'\n",
    "print_result(test_result)\n",
    "sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
