A clinical evaluation of a blood conservation device in medical intensive care unit patients.

OBJECTIVES This study was designed to a) document the efficacy of a device intended to conserve blood in critically ill patients; b) determine the effect of this blood conservation on hemoglobin concentration and the need for blood transfusions; c) determine if the blood conservation device resulted in interference with arterial pressure waveforms; d) determine if use of the blood conservation device resulted in a difference in the number of accidental needle punctures suffered by healthcare workers.
DESIGN Prospective, randomized, controlled trial. A clinical trial using prospective, random allocation of consecutive eligible patients.
SETTING The medical intensive care unit (ICU) of a university hospital located in a large metropolitan area.
PATIENTS A total of 100 patients who were admitted to the medical ICU, required arterial line monitoring for clinical purposes, and were managed by the ICU medical service. Exclusion criteria included active bleeding or chronic renal failure at the time of ICU admission.
INTERVENTIONS Patients in the experimental group had a blood conservation device incorporated into the arterial pressure monitoring system, while patients in the control group received a conventional arterial pressure monitoring system.
MEASUREMENTS AND MAIN RESULTS Data gathered included: age; gender; ICU discharge status; the duration of ICU stay; time in the study; volume of all blood drawn, discarded, or lost due to leakage; hemoglobin concentrations; blood transfusions; and accidental needle injuries. Arterial pressure waveforms were recorded and inspected for dampening or other deformation. Mean hemoglobin concentrations were compared on ICU admission and at 12-hr intervals. Demographic and clinical characteristics of the two groups were not significantly different. The volume of blood drawn and discarded from arterial catheters was significantly lower in the blood conservation group (blood conservation device: 5.7 +/- 7.5 mL; control: 96.4 +/- 88.5 mL; p < .0001), as was the total volume of blood discarded (blood conservation device: 19.4 +/- 47.4 mL; control: 103.5 +/- 99.9 mL; p < .0001). Mean hemoglobin concentration on admission was similar in the two groups (blood conservation device group: 11.8 +/- 2.5 g/dL; control group: 12.6 +/- 2.3 g/dL). In both groups, the mean hemoglobin concentration declined most rapidly in the first 24 hrs of ICU care and, thereafter, declined more slowly. Although the mean hemoglobin concentration was higher in the blood conservation group after 6 days, statistical significance was not reached until 9.5 days of ICU care. The mean change in hemoglobin concentration (overall: 1.2 +/- 2.2 g/dL) during the study represents a statistically significant (p < .0001) decrease of 9.7%. Hemoglobin concentration during the study decreased by 1.4 +/- 2.2 g/dL in the control group and 1.0 +/- 2.3 g/dL in the blood conservation group (p = nonsignificant). Univariate and multiple regression analysis demonstrated discarded blood volume to be a significant and independent predictor of the decline in hemoglobin concentration. Transfusion requirements were similar in both groups. The blood conservation system did not alter or interfere with pressure waveforms. There were no accidental needle injuries noted.
CONCLUSIONS The conservation of blood in critically ill patients must be a high-priority concern of all healthcare workers. Our data indicate that the blood conservation system eliminates a significant factor in the decline in hemoglobin concentration. With devices as described here, there is no reason to continue the practice of wasting the blood of critically ill patients in order to prevent preanalytic error.

