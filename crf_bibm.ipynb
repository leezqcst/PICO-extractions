{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF BIBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from crf import *\n",
    "from crf_support import compare_tags, filter_phrase\n",
    "\n",
    "from preproccess_data_bibm2011 import get_all_data, get_all_data_train, get_all_data_dev, get_all_data_test\n",
    "\n",
    "import os, time\n",
    "\n",
    "from features_generator import abstracts2features, sanity_check\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = 'P'\n",
    "eval_tags = [tag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genia_tags(data_set):\n",
    "    switcher = {\n",
    "        'train': (0, 95),\n",
    "        'dev': (95, 122),\n",
    "        'test': (122, 135), \n",
    "    }\n",
    "    start, end = switcher[data_set]\n",
    "    \n",
    "    f = open('./bibm2011corpus-master/abstracts_2.txt', 'r')\n",
    "    abstract_list = f.readlines()\n",
    "    f.close()\n",
    "    abstract_list = [x.strip() for x in abstract_list]\n",
    "    final_list = abstract_list[start:end]\n",
    "    \n",
    "    genia_tags = []\n",
    "    \n",
    "    for abstract_path in final_list:\n",
    "        pickle_path = abstract_path[:-4] + '_genia.tag'\n",
    "        pickle_file = open(pickle_path, 'rb')\n",
    "        abstract_genia_tags = pickle.load(pickle_file)\n",
    "        \n",
    "        genia_tags.append(abstract_genia_tags)\n",
    "    return genia_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Get train data\n",
    "train_tokens, train_tags = get_all_data_train()\n",
    "train_genia_tags = get_genia_tags('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get dev data\n",
    "dev_tokens, dev_tags = get_all_data_dev()\n",
    "dev_genia_tags = get_genia_tags('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get test data\n",
    "test_tokens, test_tags = get_all_data_test()\n",
    "test_genia_tags = get_genia_tags('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pubmed_w2v_name = 'PubMed-w2v.bin'\n",
    "pubmed_w2v = Word2Vec.load_word2vec_format(pubmed_w2v_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pubmed_wiki_w2v_name = 'wikipedia-pubmed-and-PMC-w2v.bin'\n",
    "pubmed_wiki_w2v = Word2Vec.load_word2vec_format(pubmed_wiki_w2v_name, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set options\n",
    "big_options_string = 'left_neighbors=3 right_neighbors=3 inside_paren pos chunk iob named_entity \\\n",
    "inside_paren_neighbors pos_neighbors chunk_neighbors iob_neighbors named_entity_neighbors \\\n",
    "chunk_end chunk_end_neighbors same_chunk_neighbors \\\n",
    "one_hot one_hot_neighbors w2v_model=pubmed w2v w2v_neighbors w2v_size=10 cosine_simil cosine_simil_neighbors \\\n",
    "isupper isupper_neighbors istitle istitle_neighbors'\n",
    "\n",
    "options_string = 'left_neighbors=3 right_neighbors=3 one_hot one_hot_neighbors \\\n",
    "inside_paren pos chunk iob named_entity \\\n",
    "inside_paren_neighbors pos_neighbors chunk_neighbors iob_neighbors named_entity_neighbors \\\n",
    "chunk_end chunk_end_neighbors same_chunk_neighbors \\\n",
    "w2v_model=pubmed_wiki w2v w2v_neighbors w2v_size=30 \\\n",
    "cosine_simil cosine_simil_neighbors \\\n",
    "isupper isupper_neighbors istitle istitle_neighbors'\n",
    "\n",
    "w2v=pubmed_wiki_w2v\n",
    "\n",
    "features_name = 'P8bibm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94: ['Effect', 'of', 'beta']\n"
     ]
    }
   ],
   "source": [
    "# Compute features for train\n",
    "train_features = abstracts2features(train_tokens, train_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26: ['Mobilisation', 'with', 'movement']\n"
     ]
    }
   ],
   "source": [
    "# Compute features for dev\n",
    "dev_features = abstracts2features(dev_tokens, dev_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12: ['OBJECTIVE', ':', 'To']\n"
     ]
    }
   ],
   "source": [
    "# Compute features for test\n",
    "test_features = abstracts2features(test_tokens, test_genia_tags, w2v=w2v, options_string=options_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts: 95\n",
      "Number of tokens:    31422\n",
      "Number of features:  8938499 \n",
      "\n",
      "Avg tokens per abstract: 330\n",
      "Avg features per token:  284 \n",
      "\n",
      "Max features per token:  286\n",
      "Min features per token:  161\n"
     ]
    }
   ],
   "source": [
    "# For debug\n",
    "sanity_check(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 0.01, L2: 0.01, scores: {'P': (0.9230769230769231, 0.4044943820224719, 0.5625)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 0.01, L2: 0.1, scores: {'P': (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 0.01, L2: 1, scores: {'P': (0.9145907473309609, 0.3609550561797753, 0.5176233635448138)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 0.1, L2: 0.01, scores: {'P': (0.9230769230769231, 0.4044943820224719, 0.5625)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 0.1, L2: 0.1, scores: {'P': (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 0.1, L2: 1, scores: {'P': (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 1, L2: 0.01, scores: {'P': (0.9111111111111111, 0.3455056179775281, 0.5010183299389003)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 1, L2: 0.1, scores: {'P': (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)}\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "L1: 1, L2: 1, scores: {'P': (0.9036144578313253, 0.3160112359550562, 0.4682622268470344)}\n",
      "--- 344.35304904 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run grid search\n",
    "grid_file_name = 'crf_results/{}_grid'.format(features_name)\n",
    "num_iters = 200\n",
    "l1_list = [0.01, 0.1, 1]\n",
    "l2_list = [0.01, 0.1, 1]\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_result = grid_search(train_features, train_tags, dev_features, dev_tags,\\\n",
    "                                 num_iters, l1_list, l2_list, eval_tags, file_name=grid_file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "os.remove(grid_file_name + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: 0.1, L2: 0.01\n",
      "P: (0.9230769230769231, 0.4044943820224719, 0.5625)\n",
      "L1: 0.01, L2: 0.01\n",
      "P: (0.9230769230769231, 0.4044943820224719, 0.5625)\n",
      "L1: 0.1, L2: 0.1\n",
      "P: (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)\n",
      "L1: 0.1, L2: 1\n",
      "P: (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)\n",
      "L1: 1, L2: 0.1\n",
      "P: (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)\n",
      "L1: 0.01, L2: 0.1\n",
      "P: (0.9205298013245033, 0.3904494382022472, 0.5483234714003945)\n",
      "L1: 0.01, L2: 1\n",
      "P: (0.9145907473309609, 0.3609550561797753, 0.5176233635448138)\n",
      "L1: 1, L2: 0.01\n",
      "P: (0.9111111111111111, 0.3455056179775281, 0.5010183299389003)\n",
      "L1: 1, L2: 1\n",
      "P: (0.9036144578313253, 0.3160112359550562, 0.4682622268470344)\n"
     ]
    }
   ],
   "source": [
    "# Sort result\n",
    "sorted_result = sort_by_metric(grid_search_result, tag, metric='f1')\n",
    "print_result(sorted_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set options\n",
    "num_iters = 200\n",
    "l1 = 0.1\n",
    "l2 = 0.01\n",
    "file_name = 'crf_results/{}'.format(features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "--- 39.9441611767 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run CRF\n",
    "start_time = time.time()\n",
    "crf_result = get_crf_results(train_features, train_tags, dev_features, dev_tags, num_iters, l1, l2, eval_tags,\n",
    "                             file_name=file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: (0.9230769230769231, 0.4044943820224719, 0.5625)\n"
     ]
    }
   ],
   "source": [
    "# Print result\n",
    "print_result(crf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get model from file\n",
    "tagger = get_tagger(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "P      -> P       0.041363\n",
      "None   -> None    -0.097811\n",
      "P      -> None    -7.264975\n",
      "None   -> P       -8.233716\n",
      "\n",
      "Top positive:\n",
      "4.927603 None   word[-1]:PARTICIPANTS\n",
      "2.855721 P      word[-2]:PARTICIPANTS\n",
      "2.396066 P      word[1]:INTERVENTIONS\n",
      "2.058474 P      word[1]:Group\n",
      "1.931018 P      word[-3]:NHS\n",
      "1.811934 None   word[-2]:controlled\n",
      "1.611998 P      word[1]:INTERVENTION\n",
      "1.556044 None   word[0]:INTERVENTION\n",
      "1.485613 P      word[-3]:PARTICIPANTS\n",
      "1.418782 None   word[0]:INTERVENTIONS\n",
      "1.407665 P      word[-3]:newspapers\n",
      "1.369649 None   word[-3]:followed\n",
      "1.342317 P      word[1]:Training\n",
      "1.341184 None   word[-1]:randomisation.\n",
      "1.326098 P      word[3]:clusters\n",
      "1.316158 P      word[1]:Expectant\n",
      "1.316158 P      word[-2]:incomplete\n",
      "1.295212 None   chunk[-2]:PRT\n",
      "1.272041 None   word[2]:closure\n",
      "1.271684 P      word[-2]:Oxford\n",
      "\n",
      "Top negative:\n",
      "-0.897128 None   word[-1]:clinics.\n",
      "-0.928468 None   word[-2]:Kingdom\n",
      "-0.938274 None   word[3]:1\n",
      "-0.944144 None   word[3]:30\n",
      "-0.946226 None   word[2]:were\n",
      "-0.962392 None   word[2]:recruited\n",
      "-0.983841 None   word[3]:MEASURES\n",
      "-1.019208 None   word[3]:estimates\n",
      "-1.032134 None   word[2]:early\n",
      "-1.162282 P      word[2]:of\n",
      "-1.166055 None   word[3]:included\n",
      "-1.228852 P      word[-3]:people\n",
      "-1.326098 None   word[3]:clusters\n",
      "-1.418782 P      word[0]:INTERVENTIONS\n",
      "-1.485613 None   word[-3]:PARTICIPANTS\n",
      "-1.556044 P      word[0]:INTERVENTION\n",
      "-1.611998 None   word[1]:INTERVENTION\n",
      "-1.931018 None   word[-3]:NHS\n",
      "-2.396066 None   word[1]:INTERVENTIONS\n",
      "-2.855721 None   word[-2]:PARTICIPANTS\n"
     ]
    }
   ],
   "source": [
    "# For debug\n",
    "print_model_info(tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.9230769230769231, 0.4044943820224719, 0.5625)\n",
      "train:\n",
      "P: (1.0, 1.0, 1.0)\n",
      "test:\n",
      "P: (1.0, 0.42011834319526625, 0.5916666666666667)\n"
     ]
    }
   ],
   "source": [
    "# Predict dev tags\n",
    "pred_dev_tags = predict_tags(tagger, dev_features)\n",
    "\n",
    "# Evaluate dev tags\n",
    "dev_result = evaluate_prediction(pred_dev_tags, dev_tags, eval_tags)\n",
    "print 'dev:'\n",
    "print_result(dev_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict train tags\n",
    "pred_train_tags = predict_tags(tagger, train_features)\n",
    "\n",
    "# Evaluate train tags\n",
    "train_result = evaluate_prediction(pred_train_tags, train_tags, eval_tags)\n",
    "print 'train:'\n",
    "print_result(train_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Predict test tags\n",
    "pred_test_tags = predict_tags(tagger, test_features)\n",
    "\n",
    "# Evaluate test tags\n",
    "test_result = evaluate_prediction(pred_test_tags, test_tags, eval_tags)\n",
    "print 'test:'\n",
    "print_result(test_result)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On fold 0\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 1\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 2\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 3\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "On fold 4\n",
      "Adding data...\n",
      "Training model...\n",
      "Done!\n",
      "--- 143.331276894 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run K-fold\n",
    "kfold_file_name = 'crf_results/{}_kfold'.format(features_name)\n",
    "\n",
    "start_time = time.time()\n",
    "kfold_result = get_kfold_results(train_features, train_tags, num_iters, l1, l2, eval_tags,\\\n",
    "                                 file_name=kfold_file_name, save=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "os.remove(kfold_file_name + '.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "P: (0.9361702127659575, 0.20657276995305165, 0.3384615384615385)\n",
      "Fold 1\n",
      "P: (0.8087248322147651, 0.9377431906614786, 0.8684684684684686)\n",
      "Fold 2\n",
      "P: (0.8820754716981132, 0.9211822660098522, 0.9012048192771083)\n",
      "Fold 3\n",
      "P: (0.6019417475728155, 0.23076923076923078, 0.3336322869955157)\n",
      "Fold 4\n",
      "P: (0.7298578199052133, 0.5992217898832685, 0.6581196581196581)\n",
      "Average\n",
      "P: (0.79175401683137281, 0.57909784945537646, 0.61997735426445777)\n"
     ]
    }
   ],
   "source": [
    "# Print all results\n",
    "print_result(kfold_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a sample prediction for an abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_with_spaces(l, spaces):\n",
    "    # This pads strings to be of space length and aligned left\n",
    "    formatter = lambda space: '{:' + str(space) + '}'\n",
    "    \n",
    "    for sublist in l:\n",
    "        print ''.join([formatter(space).format(string) for string, space in zip(sublist, spaces)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 300\n",
    "print_with_spaces(zip(dev_tokens[i], dev_tags[i], pred_dev_tags[i]), [25, 5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 predicted intervals:\n",
      "Number of type Identical      : 15\n",
      "Number of type Subinterval    : 2\n",
      "Number of type Superinterval  : 1\n",
      "Number of type Overlapping    : 0\n",
      "Number of type Non-overlapping: 0\n",
      "\n",
      "There are 312 predicted tokens:\n",
      "Number of type Identical      : 210\n",
      "Number of type Subinterval    : 64\n",
      "Number of type Superinterval  : 38\n",
      "Number of type Overlapping    : 0\n",
      "Number of type Non-overlapping: 0\n",
      "\n",
      "There are 21 gold intervals:\n",
      "Number of type Identical      : 15\n",
      "Number of type Subinterval    : 1\n",
      "Number of type Superinterval  : 2\n",
      "Number of type Overlapping    : 0\n",
      "Number of type Non-overlapping: 3\n",
      "\n",
      "There are 712 gold tokens:\n",
      "Number of type Identical      : 210\n",
      "Number of type Subinterval    : 14\n",
      "Number of type Superinterval  : 420\n",
      "Number of type Overlapping    : 0\n",
      "Number of type Non-overlapping: 68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_tags(pred_dev_tags, dev_tags, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict evaluation to noun phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev:\n",
      "P: (0.9336734693877551, 0.3969631236442516, 0.5570776255707763)\n",
      "train:\n",
      "P: (1.0, 1.0, 1.0)\n",
      "test:\n",
      "P: (1.0, 0.4474885844748858, 0.6182965299684543)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate dev tags\n",
    "dev_result = evaluate_prediction(filter_phrase(pred_dev_tags, dev_genia_tags),\\\n",
    "                                 filter_phrase(dev_tags, dev_genia_tags),\\\n",
    "                                 eval_tags)\n",
    "print 'dev:'\n",
    "print_result(dev_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Evaluate train tags\n",
    "train_result = evaluate_prediction(filter_phrase(pred_train_tags, train_genia_tags),\\\n",
    "                                   filter_phrase(train_tags, train_genia_tags),\\\n",
    "                                   eval_tags)\n",
    "print 'train:'\n",
    "print_result(train_result)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Evaluate test tags\n",
    "test_result = evaluate_prediction(filter_phrase(pred_test_tags, test_genia_tags),\\\n",
    "                                  filter_phrase(test_tags, test_genia_tags),\\\n",
    "                                  eval_tags)\n",
    "print 'test:'\n",
    "print_result(test_result)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
